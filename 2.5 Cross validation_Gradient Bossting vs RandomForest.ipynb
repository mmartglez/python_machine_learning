{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Cross validation: Gradient Bossting vs RandomForest\n",
    "\n",
    "Realicemos una predicción basada en un Gradient Bossting. \n",
    "Se parte de los datos analizados, normalizados y acotados logrados en el punto 0, para el training.\n",
    "\n",
    "En este caso no vamos a jugar tanto con los parámetros, como con los modelos que existen. Utilizaremos uno de tipo arboles de decisión (randomforest) y uno de regresiones lineales (Gradient Bossting) y veremos cual se comporta mejor de base, mediante un Cross validation\n",
    "\n",
    "\n",
    "## Importación de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.805765</td>\n",
       "      <td>729.805765</td>\n",
       "      <td>56.877145</td>\n",
       "      <td>10460.434454</td>\n",
       "      <td>6.094715</td>\n",
       "      <td>5.576527</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1984.818806</td>\n",
       "      <td>439.128346</td>\n",
       "      <td>46.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.069321</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.402158</td>\n",
       "      <td>421.402158</td>\n",
       "      <td>42.339638</td>\n",
       "      <td>9862.564977</td>\n",
       "      <td>1.376542</td>\n",
       "      <td>1.113638</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>20.640669</td>\n",
       "      <td>432.964939</td>\n",
       "      <td>161.471529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.090410</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.383022</td>\n",
       "      <td>0.278112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>364.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9473.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2188.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           Id   MSSubClass        LotArea  OverallQual  \\\n",
       "count  1457.000000  1457.000000  1457.000000    1457.000000  1457.000000   \n",
       "mean    728.805765   729.805765    56.877145   10460.434454     6.094715   \n",
       "std     421.402158   421.402158    42.339638    9862.564977     1.376542   \n",
       "min       0.000000     1.000000    20.000000    1300.000000     1.000000   \n",
       "25%     364.000000   365.000000    20.000000    7540.000000     5.000000   \n",
       "50%     729.000000   730.000000    50.000000    9473.000000     6.000000   \n",
       "75%    1093.000000  1094.000000    70.000000   11600.000000     7.000000   \n",
       "max    1459.000000  1460.000000   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1457.000000  1457.000000   1457.000000  1457.000000  1457.000000   \n",
       "mean      5.576527  1971.194235   1984.818806   439.128346    46.645161   \n",
       "std       1.113638    30.190353     20.640669   432.964939   161.471529   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1972.000000   1994.000000   383.000000     0.000000   \n",
       "75%       6.000000  2000.000000   2004.000000   712.000000     0.000000   \n",
       "max       9.000000  2010.000000   2010.000000  2188.000000  1474.000000   \n",
       "\n",
       "               ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "count          ...               1457.000000   1457.000000   1457.000000   \n",
       "mean           ...                  0.003432      0.082361      0.002059   \n",
       "std            ...                  0.058500      0.275008      0.045345   \n",
       "min            ...                  0.000000      0.000000      0.000000   \n",
       "25%            ...                  0.000000      0.000000      0.000000   \n",
       "50%            ...                  0.000000      0.000000      0.000000   \n",
       "75%            ...                  0.000000      0.000000      0.000000   \n",
       "max            ...                  1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "count  1457.000000            1457.000000            1457.000000   \n",
       "mean      0.868909               0.069321               0.002745   \n",
       "std       0.337616               0.254086               0.052342   \n",
       "min       0.000000               0.000000               0.000000   \n",
       "25%       1.000000               0.000000               0.000000   \n",
       "50%       1.000000               0.000000               0.000000   \n",
       "75%       1.000000               0.000000               0.000000   \n",
       "max       1.000000               1.000000               1.000000   \n",
       "\n",
       "       SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "count           1457.000000           1457.000000           1457.000000   \n",
       "mean               0.008236              0.013727              0.821551   \n",
       "std                0.090410              0.116395              0.383022   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              1.000000   \n",
       "50%                0.000000              0.000000              1.000000   \n",
       "75%                0.000000              0.000000              1.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Partial  \n",
       "count            1457.000000  \n",
       "mean                0.084420  \n",
       "std                 0.278112  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 222 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerías a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importación de datos\n",
    "melbourne_data = pd.read_csv(\"data/PreciosCasas/train_final.csv\", sep='\\t', encoding='utf-8') \n",
    "\n",
    "# print a summary of the data in Melbourne data\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=222)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos\n",
    "\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos prededir el precio, será nuestro target, para lo cual, cogeremos unas variables como pedictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10460.434454</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1159.129032</td>\n",
       "      <td>345.560055</td>\n",
       "      <td>1.563487</td>\n",
       "      <td>2.866163</td>\n",
       "      <td>6.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9862.564977</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>372.015864</td>\n",
       "      <td>435.505117</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.816595</td>\n",
       "      <td>1.616384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7540.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9473.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11600.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3228.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1457.000000  1457.000000  1457.000000  1457.000000  1457.000000   \n",
       "mean    10460.434454  1971.194235  1159.129032   345.560055     1.563487   \n",
       "std      9862.564977    30.190353   372.015864   435.505117     0.549961   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7540.000000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9473.000000  1972.000000  1086.000000     0.000000     2.000000   \n",
       "75%     11600.000000  2000.000000  1391.000000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  3228.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1457.000000   1457.000000  \n",
       "mean       2.866163      6.510638  \n",
       "std        0.816595      1.616384  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= melbourne_data.SalePrice\n",
    "print(y.head())\n",
    "melbourne_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = melbourne_data[melbourne_predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random forest \n",
    "\n",
    "Pasamos directamente a modelar sin más (el objeto no son los parámetros, es comparar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "from  sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Separamos los datos en dos grupos, \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.133609440716\n"
     ]
    }
   ],
   "source": [
    "# 1) RandomForest\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(X_train, y_train)\n",
    "melb_preds = forest_model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, melb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14156713  0.14520264  0.13336128]\n",
      "[ 0.73456125  0.76459303  0.77818127]\n"
     ]
    }
   ],
   "source": [
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2']) \n",
    "    \n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo GradientBoostingRegressor \n",
    "\n",
    "Pasamos directamente a modelar sin más (el objeto no son los parámetros, es comparar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13375915  0.13823556  0.12399015]\n",
      "[ 0.75139868  0.7800183   0.81837829]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoras en el modelo - Hiperparámetros\n",
    "\n",
    "Tenemos los dos modelos y se comportan de forma bastante similar (parecía que uno lineal podía ser mejor, pero no termina de ser tan obvio), así que vamos a hacer mirar que parámetros son los que debo cambiar para mi modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.6, 0.7, 0.8], 'min_weight_fraction_leaf': [0.2, 0.1, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.60, 0.7, 0.80],'min_weight_fraction_leaf':[0.20, 0.1, 0.05]}\n",
    "gbr = GradientBoostingRegressor()\n",
    "clf = GridSearchCV(gbr, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.0609986 ,  0.05113602,  0.05222217,  0.09214973,  0.08438269,\n",
       "         0.08170168,  0.09218542,  0.10509396,  0.09426618,  0.05707097,\n",
       "         0.06233708,  0.0645109 ,  0.08340208,  0.07685804,  0.08996288,\n",
       "         0.10349623,  0.10861866,  0.09865777,  0.06299774,  0.0649151 ,\n",
       "         0.11139361,  0.17240024,  0.17814382,  0.16331951,  0.1204435 ,\n",
       "         0.10525878,  0.10543172,  0.05417323,  0.04990101,  0.05515361,\n",
       "         0.09470089,  0.08980044,  0.08696946,  0.10188882,  0.09827542,\n",
       "         0.09439476,  0.06897259,  0.0933431 ,  0.09260909,  0.10011546,\n",
       "         0.10621397,  0.10553567,  0.11838031,  0.12657666,  0.13329109,\n",
       "         0.08023659,  0.08063094,  0.0798924 ,  0.11103646,  0.11555052,\n",
       "         0.10778944,  0.13073039,  0.13452752,  0.13723675,  0.05878297,\n",
       "         0.05907623,  0.06086405,  0.15417035,  0.15760676,  0.15160426,\n",
       "         0.09794474,  0.12026413,  0.09958625,  0.07593926,  0.06751283,\n",
       "         0.06990274,  0.10141937,  0.10395789,  0.09996454,  0.11274322,\n",
       "         0.12147522,  0.12463888,  0.08402904,  0.08398223,  0.09046896,\n",
       "         0.12014167,  0.13461264,  0.12374258,  0.15254807,  0.15665897,\n",
       "         0.15878638,  0.05692808,  0.06115262,  0.0646441 ,  0.07961432,\n",
       "         0.0837903 ,  0.08405892,  0.15877748,  0.17964141,  0.17863226,\n",
       "         0.07091244,  0.07602795,  0.10783291,  0.12080733,  0.12313795,\n",
       "         0.13032969,  0.15016341,  0.18845479,  0.13901806,  0.11972284,\n",
       "         0.20202835,  0.140378  ,  0.16581273,  0.17999967,  0.1545879 ,\n",
       "         0.18680882,  0.18948857,  0.176699  ]),\n",
       " 'mean_score_time': array([ 0.00151141,  0.00158676,  0.00159375,  0.00225631,  0.00167068,\n",
       "         0.00200303,  0.00205056,  0.00200891,  0.00205199,  0.00142169,\n",
       "         0.00155449,  0.00287596,  0.00188152,  0.00168133,  0.00190314,\n",
       "         0.00218852,  0.00215197,  0.00189821,  0.00176843,  0.00165049,\n",
       "         0.00377774,  0.00249736,  0.00222985,  0.00239682,  0.00204158,\n",
       "         0.0020504 ,  0.00206765,  0.00130574,  0.00122865,  0.00186753,\n",
       "         0.00172718,  0.00193501,  0.00189193,  0.00184449,  0.00190131,\n",
       "         0.00178305,  0.00178337,  0.00369477,  0.00335725,  0.00285618,\n",
       "         0.00226561,  0.00189654,  0.00263079,  0.00275373,  0.00230344,\n",
       "         0.00181127,  0.00170477,  0.00184274,  0.00201567,  0.00223986,\n",
       "         0.00236924,  0.00251985,  0.00258748,  0.00232561,  0.00131838,\n",
       "         0.0015707 ,  0.00144847,  0.00205723,  0.00304023,  0.00168006,\n",
       "         0.00193771,  0.00225274,  0.00154034,  0.00190687,  0.00172043,\n",
       "         0.00190401,  0.00209403,  0.00305327,  0.00221674,  0.00236464,\n",
       "         0.00326991,  0.00239627,  0.00188327,  0.00201734,  0.00211628,\n",
       "         0.00237775,  0.00270351,  0.00370351,  0.00352105,  0.00287255,\n",
       "         0.00290322,  0.00146317,  0.00149854,  0.00133944,  0.00140627,\n",
       "         0.00183193,  0.00175214,  0.00170628,  0.0024399 ,  0.00218391,\n",
       "         0.00199246,  0.00178067,  0.00270184,  0.00242575,  0.00254448,\n",
       "         0.0023466 ,  0.00409245,  0.00355951,  0.00286921,  0.00278823,\n",
       "         0.00633987,  0.00275302,  0.00719349,  0.00357699,  0.00306654,\n",
       "         0.00516677,  0.00361164,  0.00303157]),\n",
       " 'mean_test_score': array([ 0.709005  ,  0.71123011,  0.70757378,  0.71845701,  0.71843809,\n",
       "         0.71715308,  0.7197359 ,  0.71784435,  0.71610208,  0.75982521,\n",
       "         0.76310632,  0.76058105,  0.76789445,  0.76812216,  0.76476024,\n",
       "         0.77106673,  0.76936635,  0.77102761,  0.77773105,  0.77731783,\n",
       "         0.7776423 ,  0.78153283,  0.78375673,  0.77897606,  0.78754047,\n",
       "         0.78511382,  0.78181127,  0.70548398,  0.712587  ,  0.70731078,\n",
       "         0.71757147,  0.71498522,  0.715428  ,  0.7183698 ,  0.71870602,\n",
       "         0.71579037,  0.76709135,  0.76356406,  0.76163646,  0.76555965,\n",
       "         0.76634424,  0.76549431,  0.7705414 ,  0.77013114,  0.76744255,\n",
       "         0.78308619,  0.78463927,  0.77815552,  0.78238951,  0.78448724,\n",
       "         0.78251698,  0.78874752,  0.78122614,  0.78397563,  0.70661765,\n",
       "         0.7081826 ,  0.70819571,  0.71517098,  0.71549483,  0.71810756,\n",
       "         0.71910929,  0.72047117,  0.72062805,  0.76466022,  0.76638244,\n",
       "         0.76166578,  0.77129711,  0.76932888,  0.76527365,  0.77012375,\n",
       "         0.77016533,  0.77004479,  0.78253025,  0.78326614,  0.78031391,\n",
       "         0.78410483,  0.7844575 ,  0.78133079,  0.78056233,  0.78023224,\n",
       "         0.78326185,  0.70924   ,  0.70684265,  0.70817509,  0.71474275,\n",
       "         0.71798213,  0.71705228,  0.71903564,  0.71738062,  0.71914888,\n",
       "         0.76558176,  0.76097813,  0.76246383,  0.77040557,  0.76869396,\n",
       "         0.7704567 ,  0.77284897,  0.76933307,  0.76678337,  0.78354283,\n",
       "         0.78166243,  0.78481545,  0.7842926 ,  0.78232767,  0.7814848 ,\n",
       "         0.78094341,  0.78548452,  0.78278924]),\n",
       " 'mean_train_score': array([ 0.74338271,  0.74688076,  0.74393176,  0.75816653,  0.75876233,\n",
       "         0.75764411,  0.76588871,  0.76373663,  0.76310537,  0.8114005 ,\n",
       "         0.81131275,  0.80869143,  0.82562208,  0.82309524,  0.82244506,\n",
       "         0.83074798,  0.83285427,  0.83029972,  0.84122601,  0.84325974,\n",
       "         0.84210026,  0.85528739,  0.85616528,  0.8531212 ,  0.86471111,\n",
       "         0.86254264,  0.86039459,  0.74410948,  0.74571773,  0.7439006 ,\n",
       "         0.75816949,  0.75747622,  0.75659627,  0.76445238,  0.76458019,\n",
       "         0.76337449,  0.82365707,  0.82313043,  0.82240713,  0.83956966,\n",
       "         0.8405853 ,  0.83718955,  0.84752418,  0.84739212,  0.84507244,\n",
       "         0.86740941,  0.86745669,  0.86547909,  0.88295905,  0.88204685,\n",
       "         0.88063877,  0.89124872,  0.88980776,  0.88825741,  0.74603265,\n",
       "         0.74314913,  0.74328671,  0.75650373,  0.75719468,  0.75914824,\n",
       "         0.76391956,  0.76551256,  0.76467822,  0.82629945,  0.82603377,\n",
       "         0.82335617,  0.84262438,  0.84202763,  0.83985756,  0.84932034,\n",
       "         0.85061168,  0.84857736,  0.87944634,  0.87926438,  0.87616985,\n",
       "         0.89379554,  0.89555754,  0.89423203,  0.903718  ,  0.90506438,\n",
       "         0.90242657,  0.74420858,  0.74414214,  0.74330308,  0.75874255,\n",
       "         0.75860126,  0.75808635,  0.76349454,  0.76627842,  0.76449341,\n",
       "         0.82593229,  0.82546702,  0.82335896,  0.84167674,  0.84266417,\n",
       "         0.83897428,  0.84904042,  0.85087653,  0.84813866,  0.88230449,\n",
       "         0.88161521,  0.88137946,  0.90102533,  0.899809  ,  0.89867937,\n",
       "         0.91044834,  0.90899446,  0.90864888]),\n",
       " 'param_max_depth': masked_array(data = [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
       "  7 7 7 7 7 7 7 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_weight_fraction_leaf': masked_array(data = [0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100\n",
       "  100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120\n",
       "  120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120\n",
       "  70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_subsample': masked_array(data = [0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8}],\n",
       " 'rank_test_score': array([100,  98, 104,  80,  81,  88,  75,  85,  90,  72,  66,  71,  53,\n",
       "         52,  63,  39,  48,  40,  34,  36,  35,  24,  12,  32,   2,   4,\n",
       "         22, 108,  97, 105,  86,  95,  93,  82,  79,  91,  55,  65,  69,\n",
       "         60,  58,  61,  41,  45,  54,  16,   6,  33,  20,   7,  19,   1,\n",
       "         27,  11, 107, 102, 101,  94,  92,  83,  77,  74,  73,  64,  57,\n",
       "         68,  38,  50,  62,  46,  44,  47,  18,  14,  30,  10,   8,  26,\n",
       "         29,  31,  15,  99, 106, 103,  96,  84,  89,  78,  87,  76,  59,\n",
       "         70,  67,  43,  51,  42,  37,  49,  56,  13,  23,   5,   9,  21,\n",
       "         25,  28,   3,  17], dtype=int32),\n",
       " 'split0_test_score': array([ 0.67829662,  0.68340698,  0.67614063,  0.68351072,  0.67978848,\n",
       "         0.68268422,  0.67995135,  0.67717067,  0.67747526,  0.72797393,\n",
       "         0.73288227,  0.72941179,  0.74117496,  0.73759058,  0.73307094,\n",
       "         0.74649354,  0.74057997,  0.7394603 ,  0.73751446,  0.74682268,\n",
       "         0.74914102,  0.74958746,  0.7532206 ,  0.74788273,  0.75240944,\n",
       "         0.75397966,  0.74876033,  0.6686827 ,  0.68210341,  0.67536126,\n",
       "         0.68047877,  0.68213599,  0.67210331,  0.68412954,  0.6803734 ,\n",
       "         0.67896263,  0.74003218,  0.73420122,  0.73097819,  0.733621  ,\n",
       "         0.73796728,  0.73799392,  0.73905522,  0.73982272,  0.73679853,\n",
       "         0.75231161,  0.75206812,  0.74817023,  0.75027974,  0.75241672,\n",
       "         0.752508  ,  0.76168686,  0.75377519,  0.75294599,  0.67307315,\n",
       "         0.67529484,  0.67645982,  0.68209139,  0.67852329,  0.67885748,\n",
       "         0.68356792,  0.67888149,  0.68124677,  0.73720609,  0.74022723,\n",
       "         0.7296408 ,  0.74148419,  0.73854057,  0.72886174,  0.74474391,\n",
       "         0.73765466,  0.74620228,  0.75660988,  0.74784387,  0.75177608,\n",
       "         0.7552546 ,  0.75957743,  0.75191778,  0.73860479,  0.74924999,\n",
       "         0.75022609,  0.67438176,  0.67523322,  0.67230884,  0.67809544,\n",
       "         0.67898579,  0.68007901,  0.67721464,  0.68229786,  0.68023011,\n",
       "         0.74238006,  0.73230174,  0.73590563,  0.74084289,  0.7371778 ,\n",
       "         0.74255079,  0.74489097,  0.73813509,  0.73828437,  0.74977481,\n",
       "         0.74955959,  0.75050751,  0.75120921,  0.74863551,  0.74475001,\n",
       "         0.74826432,  0.75264192,  0.74831397]),\n",
       " 'split0_train_score': array([ 0.76108153,  0.76451927,  0.75948547,  0.77410956,  0.77624447,\n",
       "         0.77343905,  0.7811241 ,  0.78092224,  0.78071744,  0.82203807,\n",
       "         0.82245024,  0.82140565,  0.83603117,  0.83256884,  0.83469054,\n",
       "         0.84002623,  0.84337457,  0.84190178,  0.85220503,  0.85711956,\n",
       "         0.85300157,  0.86720662,  0.86544274,  0.86428872,  0.87576384,\n",
       "         0.8724076 ,  0.87188028,  0.7584141 ,  0.76483851,  0.760689  ,\n",
       "         0.77402709,  0.77891822,  0.77323879,  0.78342411,  0.78230201,\n",
       "         0.78088633,  0.83475306,  0.83425364,  0.83480522,  0.8491923 ,\n",
       "         0.85172332,  0.84719395,  0.85954077,  0.85755563,  0.85569716,\n",
       "         0.87751803,  0.87835083,  0.87479559,  0.89802509,  0.89186989,\n",
       "         0.89113885,  0.90167538,  0.90164826,  0.89752337,  0.76359494,\n",
       "         0.75777445,  0.76094931,  0.77601644,  0.7762983 ,  0.77495882,\n",
       "         0.78388636,  0.78484372,  0.78225963,  0.83846265,  0.83789445,\n",
       "         0.83626616,  0.85210806,  0.85366577,  0.85170137,  0.860013  ,\n",
       "         0.86025535,  0.85746265,  0.88948172,  0.88936217,  0.88493108,\n",
       "         0.90392738,  0.90718206,  0.90468931,  0.91368866,  0.91417176,\n",
       "         0.91286815,  0.76234273,  0.75986964,  0.75507678,  0.77484842,\n",
       "         0.77310404,  0.77561018,  0.7803738 ,  0.78639744,  0.78093991,\n",
       "         0.83670514,  0.8345079 ,  0.83685836,  0.85084401,  0.85294607,\n",
       "         0.85102113,  0.8562856 ,  0.85809415,  0.85733985,  0.89409918,\n",
       "         0.8928586 ,  0.89262475,  0.90697566,  0.90839182,  0.9101855 ,\n",
       "         0.91917876,  0.91785255,  0.91762554]),\n",
       " 'split1_test_score': array([ 0.70905135,  0.70972971,  0.70922759,  0.72146297,  0.72085894,\n",
       "         0.71932013,  0.72646868,  0.72583626,  0.72272234,  0.7680829 ,\n",
       "         0.76808265,  0.7693418 ,  0.77122928,  0.77476195,  0.77027955,\n",
       "         0.77509751,  0.7761691 ,  0.7742572 ,  0.78207013,  0.7838611 ,\n",
       "         0.78411776,  0.78233852,  0.78921292,  0.78174656,  0.78876431,\n",
       "         0.7872874 ,  0.78349879,  0.70927249,  0.71374247,  0.70947308,\n",
       "         0.72088702,  0.71970089,  0.72237337,  0.72003745,  0.72320022,\n",
       "         0.71911547,  0.76875446,  0.7699364 ,  0.76741778,  0.77393258,\n",
       "         0.77400516,  0.77196107,  0.77587669,  0.77781877,  0.77252368,\n",
       "         0.79066112,  0.79148286,  0.78323911,  0.78710633,  0.79102179,\n",
       "         0.78827941,  0.78795696,  0.7850612 ,  0.78444435,  0.70735899,\n",
       "         0.70871188,  0.70733894,  0.71753788,  0.71995289,  0.72510522,\n",
       "         0.72319134,  0.72497156,  0.725741  ,  0.77106116,  0.77084389,\n",
       "         0.77026186,  0.77283555,  0.77944648,  0.77707157,  0.77825646,\n",
       "         0.77977836,  0.77071613,  0.78616411,  0.7900435 ,  0.78789927,\n",
       "         0.78927593,  0.78632352,  0.78687677,  0.78796054,  0.78580687,\n",
       "         0.78977585,  0.70772787,  0.7064314 ,  0.71180604,  0.71722055,\n",
       "         0.72086681,  0.72238069,  0.72785814,  0.7213248 ,  0.72289985,\n",
       "         0.77006459,  0.76618837,  0.76600552,  0.77593643,  0.77523711,\n",
       "         0.77666418,  0.77975761,  0.77763589,  0.77386518,  0.79226123,\n",
       "         0.78602399,  0.79096614,  0.78903515,  0.79219925,  0.78850845,\n",
       "         0.78855777,  0.78734475,  0.79223916]),\n",
       " 'split1_train_score': array([ 0.73769357,  0.74242685,  0.73903281,  0.75412708,  0.75207539,\n",
       "         0.75270374,  0.76455249,  0.75863038,  0.75838171,  0.81307378,\n",
       "         0.81151653,  0.80692897,  0.82769896,  0.82615746,  0.8217492 ,\n",
       "         0.83207969,  0.83248475,  0.83104303,  0.84123736,  0.84519554,\n",
       "         0.84393317,  0.85679606,  0.85883154,  0.85598425,  0.86470046,\n",
       "         0.86324985,  0.8613104 ,  0.73904542,  0.73929176,  0.73967468,\n",
       "         0.75169164,  0.75000442,  0.75204938,  0.75888227,  0.75978869,\n",
       "         0.75721013,  0.82233434,  0.82170114,  0.81974555,  0.83987732,\n",
       "         0.83963853,  0.83707152,  0.84697883,  0.84990216,  0.84543668,\n",
       "         0.86542981,  0.86651162,  0.86724148,  0.88138394,  0.8840864 ,\n",
       "         0.87996859,  0.8908793 ,  0.88899001,  0.88952825,  0.74061113,\n",
       "         0.73584919,  0.73722898,  0.75108777,  0.75424102,  0.75618757,\n",
       "         0.75726652,  0.75606268,  0.75995238,  0.82521533,  0.82503135,\n",
       "         0.82338635,  0.84342362,  0.84200612,  0.84061678,  0.85112281,\n",
       "         0.85254283,  0.84988872,  0.87662884,  0.87879126,  0.8764619 ,\n",
       "         0.89495239,  0.89364051,  0.89556892,  0.90436986,  0.90531423,\n",
       "         0.9028321 ,  0.73564159,  0.73711426,  0.73878064,  0.75553412,\n",
       "         0.75511878,  0.75342838,  0.75821371,  0.75908241,  0.75786072,\n",
       "         0.82775141,  0.82678335,  0.82077294,  0.84366876,  0.84443457,\n",
       "         0.83801283,  0.85084273,  0.85231095,  0.84957724,  0.87906132,\n",
       "         0.88066135,  0.87990959,  0.89960957,  0.9004519 ,  0.89749485,\n",
       "         0.91081432,  0.90686935,  0.9092942 ]),\n",
       " 'split2_test_score': array([ 0.73966703,  0.74055363,  0.73735311,  0.75039734,  0.75466684,\n",
       "         0.7494549 ,  0.75278768,  0.75052611,  0.74810865,  0.78341881,\n",
       "         0.78835405,  0.78298955,  0.79127911,  0.79201395,  0.79093024,\n",
       "         0.79160916,  0.79134999,  0.79936535,  0.81360855,  0.8012697 ,\n",
       "         0.79966811,  0.81267252,  0.80883668,  0.80729888,  0.82144766,\n",
       "         0.8140744 ,  0.81317467,  0.73849673,  0.74191512,  0.73709801,\n",
       "         0.75134862,  0.74311877,  0.75180733,  0.75094241,  0.75254442,\n",
       "         0.74929301,  0.79248741,  0.78655457,  0.78651341,  0.78912538,\n",
       "         0.78706029,  0.78652793,  0.7966923 ,  0.79275192,  0.79300543,\n",
       "         0.80628584,  0.81036682,  0.80305722,  0.80978246,  0.8100232 ,\n",
       "         0.80676353,  0.81659874,  0.80484203,  0.81453655,  0.73942082,\n",
       "         0.74054108,  0.74078839,  0.74588366,  0.74800832,  0.75035997,\n",
       "         0.7505686 ,  0.75756047,  0.75489637,  0.78571341,  0.78807621,\n",
       "         0.78509469,  0.79957159,  0.78999959,  0.78988764,  0.78737088,\n",
       "         0.79306296,  0.79321596,  0.80481676,  0.81191106,  0.80126638,\n",
       "         0.80778397,  0.80747156,  0.80519781,  0.81512166,  0.80563987,\n",
       "         0.80978361,  0.74561036,  0.73886333,  0.7404104 ,  0.74891227,\n",
       "         0.75409379,  0.74869714,  0.75203416,  0.74851918,  0.75431668,\n",
       "         0.78430062,  0.78444427,  0.78548034,  0.79443738,  0.79366696,\n",
       "         0.79215515,  0.79389832,  0.79222823,  0.78820055,  0.80859244,\n",
       "         0.80940372,  0.8129727 ,  0.81263344,  0.80614826,  0.81119595,\n",
       "         0.80600814,  0.8164669 ,  0.80781458]),\n",
       " 'split2_train_score': array([ 0.73137303,  0.73369615,  0.73327701,  0.74626296,  0.74796714,\n",
       "         0.74678954,  0.75198955,  0.75165726,  0.75021695,  0.79908965,\n",
       "         0.79997147,  0.79773965,  0.81313612,  0.81055941,  0.81089543,\n",
       "         0.82013803,  0.8227035 ,  0.81795437,  0.83023563,  0.82746412,\n",
       "         0.82936603,  0.84185949,  0.84422156,  0.83909064,  0.85366903,\n",
       "         0.85197048,  0.84799311,  0.73486891,  0.73302292,  0.73133811,\n",
       "         0.74878975,  0.74350602,  0.74450064,  0.75105076,  0.75164988,\n",
       "         0.75202699,  0.81388382,  0.8134365 ,  0.81267063,  0.82963936,\n",
       "         0.83039404,  0.82730319,  0.83605294,  0.83471856,  0.83408349,\n",
       "         0.85928038,  0.85750762,  0.85440021,  0.86946812,  0.87018426,\n",
       "         0.87080888,  0.88119149,  0.87878501,  0.8777206 ,  0.73389188,\n",
       "         0.73582374,  0.73168184,  0.74240698,  0.74104473,  0.74629832,\n",
       "         0.75060581,  0.75563128,  0.75182264,  0.81522035,  0.81517552,\n",
       "         0.810416  ,  0.83234147,  0.83041101,  0.82725452,  0.8368252 ,\n",
       "         0.83903686,  0.83838071,  0.87222846,  0.86963972,  0.86711657,\n",
       "         0.88250685,  0.88585005,  0.88243787,  0.89309549,  0.89570716,\n",
       "         0.89157945,  0.73464142,  0.73544251,  0.73605181,  0.74584513,\n",
       "         0.74758095,  0.74522047,  0.7518961 ,  0.7533554 ,  0.75467959,\n",
       "         0.81334032,  0.8151098 ,  0.81244559,  0.83051747,  0.83061188,\n",
       "         0.82788889,  0.83999293,  0.84222448,  0.83749889,  0.87375297,\n",
       "         0.87132567,  0.87160404,  0.89649075,  0.8905833 ,  0.88835776,\n",
       "         0.90135193,  0.90226148,  0.8990269 ]),\n",
       " 'std_fit_time': array([ 0.00338457,  0.0009488 ,  0.00170382,  0.01315835,  0.0028293 ,\n",
       "         0.00219781,  0.00513764,  0.00088025,  0.00477241,  0.00140145,\n",
       "         0.00028379,  0.00254897,  0.00110921,  0.00456828,  0.00348399,\n",
       "         0.00352914,  0.00932179,  0.0009958 ,  0.00540319,  0.00553543,\n",
       "         0.00518029,  0.08862848,  0.06979487,  0.04883456,  0.01701663,\n",
       "         0.00304791,  0.00651833,  0.00423761,  0.0037574 ,  0.00359042,\n",
       "         0.01079056,  0.00522035,  0.0091513 ,  0.00518095,  0.00545849,\n",
       "         0.00376381,  0.0050321 ,  0.02320228,  0.01291443,  0.00284673,\n",
       "         0.00930723,  0.00419739,  0.00548822,  0.00630711,  0.0138098 ,\n",
       "         0.00289866,  0.00181442,  0.00416804,  0.00282979,  0.00456949,\n",
       "         0.00928418,  0.00475686,  0.00493782,  0.00652478,  0.00139413,\n",
       "         0.00285872,  0.00470741,  0.05010607,  0.01428158,  0.01225199,\n",
       "         0.00581776,  0.01757503,  0.00385044,  0.00439951,  0.00272171,\n",
       "         0.00185241,  0.00396581,  0.00205563,  0.00068609,  0.00315733,\n",
       "         0.00812222,  0.00201777,  0.00538236,  0.006476  ,  0.00785704,\n",
       "         0.00554701,  0.00695081,  0.00568423,  0.00658096,  0.00155183,\n",
       "         0.00510071,  0.00158157,  0.00625434,  0.0011884 ,  0.0027978 ,\n",
       "         0.00671993,  0.0036393 ,  0.04645173,  0.0185119 ,  0.01272043,\n",
       "         0.00571187,  0.00210374,  0.02407545,  0.01755264,  0.00595993,\n",
       "         0.01752316,  0.02909095,  0.00878546,  0.02670807,  0.02746722,\n",
       "         0.04679801,  0.04032973,  0.04569015,  0.02595627,  0.01096508,\n",
       "         0.03247709,  0.01297969,  0.00540628]),\n",
       " 'std_score_time': array([  3.80380403e-04,   7.35361473e-05,   8.46060913e-05,\n",
       "          2.47574962e-04,   2.92961518e-04,   1.25557410e-04,\n",
       "          1.88324554e-04,   8.58353243e-05,   2.40600011e-04,\n",
       "          2.11702005e-04,   1.92994796e-04,   1.95120991e-03,\n",
       "          3.09004971e-04,   2.99642803e-04,   1.27270618e-04,\n",
       "          3.69373625e-04,   3.66658527e-05,   4.47026182e-05,\n",
       "          1.18926879e-04,   9.45413762e-05,   1.58517630e-03,\n",
       "          1.20868217e-03,   5.57411058e-04,   5.06727978e-04,\n",
       "          3.55164788e-04,   3.01546129e-04,   1.76006352e-04,\n",
       "          1.65617741e-04,   1.10090595e-04,   1.33180769e-04,\n",
       "          2.19203753e-04,   6.20370732e-04,   2.22970056e-04,\n",
       "          2.63624713e-04,   1.90949154e-04,   2.17170346e-04,\n",
       "          1.71931703e-04,   1.71275304e-03,   1.41743303e-03,\n",
       "          5.49426510e-04,   1.19072571e-04,   1.69812209e-04,\n",
       "          2.84340543e-04,   2.60666715e-04,   4.36909894e-04,\n",
       "          2.11342796e-04,   1.60043620e-04,   2.40564937e-04,\n",
       "          2.20970882e-04,   3.42660190e-04,   1.44812723e-04,\n",
       "          1.53681196e-04,   4.36863575e-04,   9.78121402e-05,\n",
       "          1.61057275e-04,   4.39813763e-04,   4.00894647e-04,\n",
       "          3.37240044e-04,   1.67493007e-03,   1.95130844e-04,\n",
       "          3.34431973e-04,   1.11039148e-03,   1.25972480e-04,\n",
       "          4.18481773e-05,   1.67480185e-04,   3.02036601e-05,\n",
       "          3.47475483e-05,   1.23922815e-03,   3.54214931e-04,\n",
       "          3.55906210e-04,   4.32130282e-04,   3.13516795e-04,\n",
       "          2.05874777e-04,   4.64750991e-04,   2.62351839e-04,\n",
       "          5.76164530e-06,   6.00474388e-04,   1.27016367e-03,\n",
       "          5.66825028e-04,   9.34122925e-05,   3.05162556e-04,\n",
       "          2.41021963e-04,   2.15846678e-04,   2.75048047e-04,\n",
       "          1.08499985e-04,   3.06458703e-04,   2.80733667e-04,\n",
       "          2.81880027e-04,   6.32570885e-04,   3.03241628e-04,\n",
       "          4.00715320e-04,   4.34225291e-04,   5.72547854e-04,\n",
       "          3.04783401e-04,   2.19475004e-04,   3.32594649e-04,\n",
       "          6.55632568e-04,   6.63372475e-04,   9.54513049e-05,\n",
       "          9.23363142e-05,   4.66913177e-03,   7.00066646e-04,\n",
       "          5.55843675e-03,   1.32792138e-03,   1.77534293e-04,\n",
       "          2.68078031e-03,   7.28071926e-04,   1.25482990e-04]),\n",
       " 'std_test_score': array([ 0.02505439,  0.02335413,  0.02501724,  0.02738895,  0.03061685,\n",
       "         0.02730205,  0.03011401,  0.03047576,  0.02921346,  0.02337628,\n",
       "         0.022918  ,  0.02273334,  0.02059041,  0.0227089 ,  0.0239412 ,\n",
       "         0.0186376 ,  0.02127763,  0.02456252,  0.03121643,  0.02270434,\n",
       "         0.02112968,  0.02576067,  0.02303063,  0.02433552,  0.02819802,\n",
       "         0.02458167,  0.0263241 ,  0.02862708,  0.0244317 ,  0.02525026,\n",
       "         0.02902732,  0.02511843,  0.03290756,  0.02730172,  0.02963458,\n",
       "         0.02880836,  0.02144702,  0.02184298,  0.02303776,  0.02342027,\n",
       "         0.02076131,  0.02033473,  0.02383075,  0.02228153,  0.02322595,\n",
       "         0.02267655,  0.02428732,  0.02269402,  0.02451978,  0.02396736,\n",
       "         0.02252139,  0.02242465,  0.02102358,  0.02514643,  0.0270914 ,\n",
       "         0.0266393 ,  0.02626902,  0.02609681,  0.02854176,  0.02960717,\n",
       "         0.02750479,  0.03227781,  0.03028391,  0.02031369,  0.01978736,\n",
       "         0.02344074,  0.02373902,  0.02219282,  0.02627335,  0.01832794,\n",
       "         0.02361959,  0.01919912,  0.01984741,  0.02659073,  0.02090416,\n",
       "         0.02175452,  0.01959717,  0.02210217,  0.03167289,  0.02335611,\n",
       "         0.0247467 ,  0.0290986 ,  0.02597851,  0.02792064,  0.02896389,\n",
       "         0.03073049,  0.02826548,  0.0311755 ,  0.02717822,  0.03036179,\n",
       "         0.01740508,  0.02160356,  0.02039315,  0.02222664,  0.02352114,\n",
       "         0.02072113,  0.02059494,  0.02285052,  0.02098444,  0.02479094,\n",
       "         0.02462516,  0.02586952,  0.02529957,  0.0244951 ,  0.02757734,\n",
       "         0.02418086,  0.02608962,  0.02519334]),\n",
       " 'std_train_score': array([ 0.01277819,  0.01297162,  0.01124635,  0.01172167,  0.01247499,\n",
       "         0.01142671,  0.0119316 ,  0.01248105,  0.01289198,  0.00944307,\n",
       "         0.00917805,  0.00974165,  0.00946153,  0.00924254,  0.00972677,\n",
       "         0.00817375,  0.00844298,  0.00979061,  0.00896897,  0.01218392,\n",
       "         0.00973582,  0.01040276,  0.00886628,  0.01048439,  0.00902017,\n",
       "         0.00835839,  0.00977337,  0.0102576 ,  0.01376051,  0.01234943,\n",
       "         0.01127542,  0.01539214,  0.01216486,  0.01379077,  0.01296424,\n",
       "         0.01256224,  0.00857102,  0.00855845,  0.00923032,  0.00798542,\n",
       "         0.00873334,  0.0081208 ,  0.00959662,  0.00949063,  0.0088275 ,\n",
       "         0.00757593,  0.00853541,  0.00841912,  0.01171142,  0.00896982,\n",
       "         0.00831319,  0.00836659,  0.00935178,  0.00813424,  0.01271777,\n",
       "         0.01034167,  0.012693  ,  0.01424543,  0.01454296,  0.01188641,\n",
       "         0.01437813,  0.01367033,  0.01286734,  0.00951954,  0.00930201,\n",
       "         0.01055331,  0.00808944,  0.00949373,  0.00999481,  0.0095518 ,\n",
       "         0.00876938,  0.00784516,  0.00731995,  0.0080586 ,  0.00727567,\n",
       "         0.00878307,  0.00881363,  0.00913317,  0.00841975,  0.00754021,\n",
       "         0.0086958 ,  0.01282928,  0.01114195,  0.00839947,  0.01205593,\n",
       "         0.01070678,  0.0128363 ,  0.01221093,  0.01441714,  0.01170172,\n",
       "         0.00962499,  0.00797376,  0.01013283,  0.00841697,  0.00920343,\n",
       "         0.00946813,  0.00677244,  0.00655768,  0.00816366,  0.00861706,\n",
       "         0.00881662,  0.00864438,  0.00439595,  0.00728449,  0.00895041,\n",
       "         0.00728237,  0.00654   ,  0.00760656])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.05,\n",
       "             n_estimators=120, presort='auto', random_state=None,\n",
       "             subsample=0.6, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "** Selección **\n",
    "\n",
    "Genial, ya sabemos que parametros hemos de coger y que son lo más optimos en este caso, veamos que se obtiene ahora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14733898  0.13308188  0.12477302  0.1646749   0.13082809  0.14818173\n",
      "  0.13017647  0.12748186  0.13811675  0.11940976]\n",
      "[ 0.66344189  0.80582753  0.76205123  0.6856104   0.82151525  0.75647054\n",
      "  0.78832318  0.79727655  0.7708478   0.82872638]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor(n_estimators= 100, max_depth=5, subsample= 0.7\n",
    "                                      ,min_weight_fraction_leaf=0.1)\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'), cv=10)\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
