{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Cross validation: Gradient Bossting vs RandomForest\n",
    "\n",
    "Realicemos una predicción basada en un Gradient Bossting. \n",
    "Se parte de los datos analizados, normalizados y acotados logrados en el punto 0, para el training.\n",
    "\n",
    "En este caso no vamos a jugar tanto con los parámetros, como con los modelos que existen. Utilizaremos uno de tipo arboles de decisión (randomforest) y uno de regresiones lineales (Gradient Bossting) y veremos cual se comporta mejor de base, mediante un Cross validation\n",
    "\n",
    "\n",
    "## Importación de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.805765</td>\n",
       "      <td>729.805765</td>\n",
       "      <td>56.877145</td>\n",
       "      <td>10460.434454</td>\n",
       "      <td>6.094715</td>\n",
       "      <td>5.576527</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1984.818806</td>\n",
       "      <td>439.128346</td>\n",
       "      <td>46.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.069321</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.402158</td>\n",
       "      <td>421.402158</td>\n",
       "      <td>42.339638</td>\n",
       "      <td>9862.564977</td>\n",
       "      <td>1.376542</td>\n",
       "      <td>1.113638</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>20.640669</td>\n",
       "      <td>432.964939</td>\n",
       "      <td>161.471529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.090410</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.383022</td>\n",
       "      <td>0.278112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>364.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9473.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2188.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           Id   MSSubClass        LotArea  OverallQual  \\\n",
       "count  1457.000000  1457.000000  1457.000000    1457.000000  1457.000000   \n",
       "mean    728.805765   729.805765    56.877145   10460.434454     6.094715   \n",
       "std     421.402158   421.402158    42.339638    9862.564977     1.376542   \n",
       "min       0.000000     1.000000    20.000000    1300.000000     1.000000   \n",
       "25%     364.000000   365.000000    20.000000    7540.000000     5.000000   \n",
       "50%     729.000000   730.000000    50.000000    9473.000000     6.000000   \n",
       "75%    1093.000000  1094.000000    70.000000   11600.000000     7.000000   \n",
       "max    1459.000000  1460.000000   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1457.000000  1457.000000   1457.000000  1457.000000  1457.000000   \n",
       "mean      5.576527  1971.194235   1984.818806   439.128346    46.645161   \n",
       "std       1.113638    30.190353     20.640669   432.964939   161.471529   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1972.000000   1994.000000   383.000000     0.000000   \n",
       "75%       6.000000  2000.000000   2004.000000   712.000000     0.000000   \n",
       "max       9.000000  2010.000000   2010.000000  2188.000000  1474.000000   \n",
       "\n",
       "               ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "count          ...               1457.000000   1457.000000   1457.000000   \n",
       "mean           ...                  0.003432      0.082361      0.002059   \n",
       "std            ...                  0.058500      0.275008      0.045345   \n",
       "min            ...                  0.000000      0.000000      0.000000   \n",
       "25%            ...                  0.000000      0.000000      0.000000   \n",
       "50%            ...                  0.000000      0.000000      0.000000   \n",
       "75%            ...                  0.000000      0.000000      0.000000   \n",
       "max            ...                  1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "count  1457.000000            1457.000000            1457.000000   \n",
       "mean      0.868909               0.069321               0.002745   \n",
       "std       0.337616               0.254086               0.052342   \n",
       "min       0.000000               0.000000               0.000000   \n",
       "25%       1.000000               0.000000               0.000000   \n",
       "50%       1.000000               0.000000               0.000000   \n",
       "75%       1.000000               0.000000               0.000000   \n",
       "max       1.000000               1.000000               1.000000   \n",
       "\n",
       "       SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "count           1457.000000           1457.000000           1457.000000   \n",
       "mean               0.008236              0.013727              0.821551   \n",
       "std                0.090410              0.116395              0.383022   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              1.000000   \n",
       "50%                0.000000              0.000000              1.000000   \n",
       "75%                0.000000              0.000000              1.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Partial  \n",
       "count            1457.000000  \n",
       "mean                0.084420  \n",
       "std                 0.278112  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 222 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerías a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importación de datos\n",
    "melbourne_data = pd.read_csv(\"data/PreciosCasas/train_final.csv\", sep='\\t', encoding='utf-8') \n",
    "\n",
    "# print a summary of the data in Melbourne data\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=222)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos\n",
    "\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos prededir el precio, será nuestro target, para lo cual, cogeremos unas variables como pedictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10460.434454</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1159.129032</td>\n",
       "      <td>345.560055</td>\n",
       "      <td>1.563487</td>\n",
       "      <td>2.866163</td>\n",
       "      <td>6.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9862.564977</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>372.015864</td>\n",
       "      <td>435.505117</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.816595</td>\n",
       "      <td>1.616384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7540.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9473.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11600.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3228.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1457.000000  1457.000000  1457.000000  1457.000000  1457.000000   \n",
       "mean    10460.434454  1971.194235  1159.129032   345.560055     1.563487   \n",
       "std      9862.564977    30.190353   372.015864   435.505117     0.549961   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7540.000000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9473.000000  1972.000000  1086.000000     0.000000     2.000000   \n",
       "75%     11600.000000  2000.000000  1391.000000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  3228.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1457.000000   1457.000000  \n",
       "mean       2.866163      6.510638  \n",
       "std        0.816595      1.616384  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= melbourne_data.SalePrice\n",
    "print(y.head())\n",
    "melbourne_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = melbourne_data[melbourne_predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random forest \n",
    "\n",
    "Pasamos directamente a modelar sin más (el objeto no son los parámetros, es comparar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "from  sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Separamos los datos en dos grupos, \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.133609440716\n"
     ]
    }
   ],
   "source": [
    "# 1) RandomForest\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(X_train, y_train)\n",
    "melb_preds = forest_model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, melb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14156713  0.14520264  0.13336128]\n",
      "[ 0.73456125  0.76459303  0.77818127]\n"
     ]
    }
   ],
   "source": [
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2']) \n",
    "    \n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo GradientBoostingRegressor \n",
    "\n",
    "Pasamos directamente a modelar sin más (el objeto no son los parámetros, es comparar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13375915  0.13823556  0.12399015]\n",
      "[ 0.75139868  0.7800183   0.81837829]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoras en el modelo - Hiperparámetros\n",
    "\n",
    "Tenemos los dos modelos y se comportan de forma bastante similar (parecía que uno lineal podía ser mejor, pero no termina de ser tan obvio), así que vamos a hacer mirar que parámetros son los que debo cambiar para mi modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.6, 0.7, 0.8], 'min_weight_fraction_leaf': [0.2, 0.1, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.60, 0.7, 0.80],'min_weight_fraction_leaf':[0.20, 0.1, 0.05]}\n",
    "gbr = GradientBoostingRegressor()\n",
    "clf = GridSearchCV(gbr, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.0609986 ,  0.05113602,  0.05222217,  0.09214973,  0.08438269,\n",
       "         0.08170168,  0.09218542,  0.10509396,  0.09426618,  0.05707097,\n",
       "         0.06233708,  0.0645109 ,  0.08340208,  0.07685804,  0.08996288,\n",
       "         0.10349623,  0.10861866,  0.09865777,  0.06299774,  0.0649151 ,\n",
       "         0.11139361,  0.17240024,  0.17814382,  0.16331951,  0.1204435 ,\n",
       "         0.10525878,  0.10543172,  0.05417323,  0.04990101,  0.05515361,\n",
       "         0.09470089,  0.08980044,  0.08696946,  0.10188882,  0.09827542,\n",
       "         0.09439476,  0.06897259,  0.0933431 ,  0.09260909,  0.10011546,\n",
       "         0.10621397,  0.10553567,  0.11838031,  0.12657666,  0.13329109,\n",
       "         0.08023659,  0.08063094,  0.0798924 ,  0.11103646,  0.11555052,\n",
       "         0.10778944,  0.13073039,  0.13452752,  0.13723675,  0.05878297,\n",
       "         0.05907623,  0.06086405,  0.15417035,  0.15760676,  0.15160426,\n",
       "         0.09794474,  0.12026413,  0.09958625,  0.07593926,  0.06751283,\n",
       "         0.06990274,  0.10141937,  0.10395789,  0.09996454,  0.11274322,\n",
       "         0.12147522,  0.12463888,  0.08402904,  0.08398223,  0.09046896,\n",
       "         0.12014167,  0.13461264,  0.12374258,  0.15254807,  0.15665897,\n",
       "         0.15878638,  0.05692808,  0.06115262,  0.0646441 ,  0.07961432,\n",
       "         0.0837903 ,  0.08405892,  0.15877748,  0.17964141,  0.17863226,\n",
       "         0.07091244,  0.07602795,  0.10783291,  0.12080733,  0.12313795,\n",
       "         0.13032969,  0.15016341,  0.18845479,  0.13901806,  0.11972284,\n",
       "         0.20202835,  0.140378  ,  0.16581273,  0.17999967,  0.1545879 ,\n",
       "         0.18680882,  0.18948857,  0.176699  ]),\n",
       " 'mean_score_time': array([ 0.00151141,  0.00158676,  0.00159375,  0.00225631,  0.00167068,\n",
       "         0.00200303,  0.00205056,  0.00200891,  0.00205199,  0.00142169,\n",
       "         0.00155449,  0.00287596,  0.00188152,  0.00168133,  0.00190314,\n",
       "         0.00218852,  0.00215197,  0.00189821,  0.00176843,  0.00165049,\n",
       "         0.00377774,  0.00249736,  0.00222985,  0.00239682,  0.00204158,\n",
       "         0.0020504 ,  0.00206765,  0.00130574,  0.00122865,  0.00186753,\n",
       "         0.00172718,  0.00193501,  0.00189193,  0.00184449,  0.00190131,\n",
       "         0.00178305,  0.00178337,  0.00369477,  0.00335725,  0.00285618,\n",
       "         0.00226561,  0.00189654,  0.00263079,  0.00275373,  0.00230344,\n",
       "         0.00181127,  0.00170477,  0.00184274,  0.00201567,  0.00223986,\n",
       "         0.00236924,  0.00251985,  0.00258748,  0.00232561,  0.00131838,\n",
       "         0.0015707 ,  0.00144847,  0.00205723,  0.00304023,  0.00168006,\n",
       "         0.00193771,  0.00225274,  0.00154034,  0.00190687,  0.00172043,\n",
       "         0.00190401,  0.00209403,  0.00305327,  0.00221674,  0.00236464,\n",
       "         0.00326991,  0.00239627,  0.00188327,  0.00201734,  0.00211628,\n",
       "         0.00237775,  0.00270351,  0.00370351,  0.00352105,  0.00287255,\n",
       "         0.00290322,  0.00146317,  0.00149854,  0.00133944,  0.00140627,\n",
       "         0.00183193,  0.00175214,  0.00170628,  0.0024399 ,  0.00218391,\n",
       "         0.00199246,  0.00178067,  0.00270184,  0.00242575,  0.00254448,\n",
       "         0.0023466 ,  0.00409245,  0.00355951,  0.00286921,  0.00278823,\n",
       "         0.00633987,  0.00275302,  0.00719349,  0.00357699,  0.00306654,\n",
       "         0.00516677,  0.00361164,  0.00303157]),\n",
       " 'mean_test_score': array([ 0.709005  ,  0.71123011,  0.70757378,  0.71845701,  0.71843809,\n",
       "         0.71715308,  0.7197359 ,  0.71784435,  0.71610208,  0.75982521,\n",
       "         0.76310632,  0.76058105,  0.76789445,  0.76812216,  0.76476024,\n",
       "         0.77106673,  0.76936635,  0.77102761,  0.77773105,  0.77731783,\n",
       "         0.7776423 ,  0.78153283,  0.78375673,  0.77897606,  0.78754047,\n",
       "         0.78511382,  0.78181127,  0.70548398,  0.712587  ,  0.70731078,\n",
       "         0.71757147,  0.71498522,  0.715428  ,  0.7183698 ,  0.71870602,\n",
       "         0.71579037,  0.76709135,  0.76356406,  0.76163646,  0.76555965,\n",
       "         0.76634424,  0.76549431,  0.7705414 ,  0.77013114,  0.76744255,\n",
       "         0.78308619,  0.78463927,  0.77815552,  0.78238951,  0.78448724,\n",
       "         0.78251698,  0.78874752,  0.78122614,  0.78397563,  0.70661765,\n",
       "         0.7081826 ,  0.70819571,  0.71517098,  0.71549483,  0.71810756,\n",
       "         0.71910929,  0.72047117,  0.72062805,  0.76466022,  0.76638244,\n",
       "         0.76166578,  0.77129711,  0.76932888,  0.76527365,  0.77012375,\n",
       "         0.77016533,  0.77004479,  0.78253025,  0.78326614,  0.78031391,\n",
       "         0.78410483,  0.7844575 ,  0.78133079,  0.78056233,  0.78023224,\n",
       "         0.78326185,  0.70924   ,  0.70684265,  0.70817509,  0.71474275,\n",
       "         0.71798213,  0.71705228,  0.71903564,  0.71738062,  0.71914888,\n",
       "         0.76558176,  0.76097813,  0.76246383,  0.77040557,  0.76869396,\n",
       "         0.7704567 ,  0.77284897,  0.76933307,  0.76678337,  0.78354283,\n",
       "         0.78166243,  0.78481545,  0.7842926 ,  0.78232767,  0.7814848 ,\n",
       "         0.78094341,  0.78548452,  0.78278924]),\n",
       " 'mean_train_score': array([ 0.74338271,  0.74688076,  0.74393176,  0.75816653,  0.75876233,\n",
       "         0.75764411,  0.76588871,  0.76373663,  0.76310537,  0.8114005 ,\n",
       "         0.81131275,  0.80869143,  0.82562208,  0.82309524,  0.82244506,\n",
       "         0.83074798,  0.83285427,  0.83029972,  0.84122601,  0.84325974,\n",
       "         0.84210026,  0.85528739,  0.85616528,  0.8531212 ,  0.86471111,\n",
       "         0.86254264,  0.86039459,  0.74410948,  0.74571773,  0.7439006 ,\n",
       "         0.75816949,  0.75747622,  0.75659627,  0.76445238,  0.76458019,\n",
       "         0.76337449,  0.82365707,  0.82313043,  0.82240713,  0.83956966,\n",
       "         0.8405853 ,  0.83718955,  0.84752418,  0.84739212,  0.84507244,\n",
       "         0.86740941,  0.86745669,  0.86547909,  0.88295905,  0.88204685,\n",
       "         0.88063877,  0.89124872,  0.88980776,  0.88825741,  0.74603265,\n",
       "         0.74314913,  0.74328671,  0.75650373,  0.75719468,  0.75914824,\n",
       "         0.76391956,  0.76551256,  0.76467822,  0.82629945,  0.82603377,\n",
       "         0.82335617,  0.84262438,  0.84202763,  0.83985756,  0.84932034,\n",
       "         0.85061168,  0.84857736,  0.87944634,  0.87926438,  0.87616985,\n",
       "         0.89379554,  0.89555754,  0.89423203,  0.903718  ,  0.90506438,\n",
       "         0.90242657,  0.74420858,  0.74414214,  0.74330308,  0.75874255,\n",
       "         0.75860126,  0.75808635,  0.76349454,  0.76627842,  0.76449341,\n",
       "         0.82593229,  0.82546702,  0.82335896,  0.84167674,  0.84266417,\n",
       "         0.83897428,  0.84904042,  0.85087653,  0.84813866,  0.88230449,\n",
       "         0.88161521,  0.88137946,  0.90102533,  0.899809  ,  0.89867937,\n",
       "         0.91044834,  0.90899446,  0.90864888]),\n",
       " 'param_max_depth': masked_array(data = [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
       "  7 7 7 7 7 7 7 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_weight_fraction_leaf': masked_array(data = [0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100\n",
       "  100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120\n",
       "  120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120\n",
       "  70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_subsample': masked_array(data = [0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8}],\n",
       " 'rank_test_score': array([100,  98, 104,  80,  81,  88,  75,  85,  90,  72,  66,  71,  53,\n",
       "         52,  63,  39,  48,  40,  34,  36,  35,  24,  12,  32,   2,   4,\n",
       "         22, 108,  97, 105,  86,  95,  93,  82,  79,  91,  55,  65,  69,\n",
       "         60,  58,  61,  41,  45,  54,  16,   6,  33,  20,   7,  19,   1,\n",
       "         27,  11, 107, 102, 101,  94,  92,  83,  77,  74,  73,  64,  57,\n",
       "         68,  38,  50,  62,  46,  44,  47,  18,  14,  30,  10,   8,  26,\n",
       "         29,  31,  15,  99, 106, 103,  96,  84,  89,  78,  87,  76,  59,\n",
       "         70,  67,  43,  51,  42,  37,  49,  56,  13,  23,   5,   9,  21,\n",
       "         25,  28,   3,  17], dtype=int32),\n",
       " 'split0_test_score': array([ 0.67829662,  0.68340698,  0.67614063,  0.68351072,  0.67978848,\n",
       "         0.68268422,  0.67995135,  0.67717067,  0.67747526,  0.72797393,\n",
       "         0.73288227,  0.72941179,  0.74117496,  0.73759058,  0.73307094,\n",
       "         0.74649354,  0.74057997,  0.7394603 ,  0.73751446,  0.74682268,\n",
       "         0.74914102,  0.74958746,  0.7532206 ,  0.74788273,  0.75240944,\n",
       "         0.75397966,  0.74876033,  0.6686827 ,  0.68210341,  0.67536126,\n",
       "         0.68047877,  0.68213599,  0.67210331,  0.68412954,  0.6803734 ,\n",
       "         0.67896263,  0.74003218,  0.73420122,  0.73097819,  0.733621  ,\n",
       "         0.73796728,  0.73799392,  0.73905522,  0.73982272,  0.73679853,\n",
       "         0.75231161,  0.75206812,  0.74817023,  0.75027974,  0.75241672,\n",
       "         0.752508  ,  0.76168686,  0.75377519,  0.75294599,  0.67307315,\n",
       "         0.67529484,  0.67645982,  0.68209139,  0.67852329,  0.67885748,\n",
       "         0.68356792,  0.67888149,  0.68124677,  0.73720609,  0.74022723,\n",
       "         0.7296408 ,  0.74148419,  0.73854057,  0.72886174,  0.74474391,\n",
       "         0.73765466,  0.74620228,  0.75660988,  0.74784387,  0.75177608,\n",
       "         0.7552546 ,  0.75957743,  0.75191778,  0.73860479,  0.74924999,\n",
       "         0.75022609,  0.67438176,  0.67523322,  0.67230884,  0.67809544,\n",
       "         0.67898579,  0.68007901,  0.67721464,  0.68229786,  0.68023011,\n",
       "         0.74238006,  0.73230174,  0.73590563,  0.74084289,  0.7371778 ,\n",
       "         0.74255079,  0.74489097,  0.73813509,  0.73828437,  0.74977481,\n",
       "         0.74955959,  0.75050751,  0.75120921,  0.74863551,  0.74475001,\n",
       "         0.74826432,  0.75264192,  0.74831397]),\n",
       " 'split0_train_score': array([ 0.76108153,  0.76451927,  0.75948547,  0.77410956,  0.77624447,\n",
       "         0.77343905,  0.7811241 ,  0.78092224,  0.78071744,  0.82203807,\n",
       "         0.82245024,  0.82140565,  0.83603117,  0.83256884,  0.83469054,\n",
       "         0.84002623,  0.84337457,  0.84190178,  0.85220503,  0.85711956,\n",
       "         0.85300157,  0.86720662,  0.86544274,  0.86428872,  0.87576384,\n",
       "         0.8724076 ,  0.87188028,  0.7584141 ,  0.76483851,  0.760689  ,\n",
       "         0.77402709,  0.77891822,  0.77323879,  0.78342411,  0.78230201,\n",
       "         0.78088633,  0.83475306,  0.83425364,  0.83480522,  0.8491923 ,\n",
       "         0.85172332,  0.84719395,  0.85954077,  0.85755563,  0.85569716,\n",
       "         0.87751803,  0.87835083,  0.87479559,  0.89802509,  0.89186989,\n",
       "         0.89113885,  0.90167538,  0.90164826,  0.89752337,  0.76359494,\n",
       "         0.75777445,  0.76094931,  0.77601644,  0.7762983 ,  0.77495882,\n",
       "         0.78388636,  0.78484372,  0.78225963,  0.83846265,  0.83789445,\n",
       "         0.83626616,  0.85210806,  0.85366577,  0.85170137,  0.860013  ,\n",
       "         0.86025535,  0.85746265,  0.88948172,  0.88936217,  0.88493108,\n",
       "         0.90392738,  0.90718206,  0.90468931,  0.91368866,  0.91417176,\n",
       "         0.91286815,  0.76234273,  0.75986964,  0.75507678,  0.77484842,\n",
       "         0.77310404,  0.77561018,  0.7803738 ,  0.78639744,  0.78093991,\n",
       "         0.83670514,  0.8345079 ,  0.83685836,  0.85084401,  0.85294607,\n",
       "         0.85102113,  0.8562856 ,  0.85809415,  0.85733985,  0.89409918,\n",
       "         0.8928586 ,  0.89262475,  0.90697566,  0.90839182,  0.9101855 ,\n",
       "         0.91917876,  0.91785255,  0.91762554]),\n",
       " 'split1_test_score': array([ 0.70905135,  0.70972971,  0.70922759,  0.72146297,  0.72085894,\n",
       "         0.71932013,  0.72646868,  0.72583626,  0.72272234,  0.7680829 ,\n",
       "         0.76808265,  0.7693418 ,  0.77122928,  0.77476195,  0.77027955,\n",
       "         0.77509751,  0.7761691 ,  0.7742572 ,  0.78207013,  0.7838611 ,\n",
       "         0.78411776,  0.78233852,  0.78921292,  0.78174656,  0.78876431,\n",
       "         0.7872874 ,  0.78349879,  0.70927249,  0.71374247,  0.70947308,\n",
       "         0.72088702,  0.71970089,  0.72237337,  0.72003745,  0.72320022,\n",
       "         0.71911547,  0.76875446,  0.7699364 ,  0.76741778,  0.77393258,\n",
       "         0.77400516,  0.77196107,  0.77587669,  0.77781877,  0.77252368,\n",
       "         0.79066112,  0.79148286,  0.78323911,  0.78710633,  0.79102179,\n",
       "         0.78827941,  0.78795696,  0.7850612 ,  0.78444435,  0.70735899,\n",
       "         0.70871188,  0.70733894,  0.71753788,  0.71995289,  0.72510522,\n",
       "         0.72319134,  0.72497156,  0.725741  ,  0.77106116,  0.77084389,\n",
       "         0.77026186,  0.77283555,  0.77944648,  0.77707157,  0.77825646,\n",
       "         0.77977836,  0.77071613,  0.78616411,  0.7900435 ,  0.78789927,\n",
       "         0.78927593,  0.78632352,  0.78687677,  0.78796054,  0.78580687,\n",
       "         0.78977585,  0.70772787,  0.7064314 ,  0.71180604,  0.71722055,\n",
       "         0.72086681,  0.72238069,  0.72785814,  0.7213248 ,  0.72289985,\n",
       "         0.77006459,  0.76618837,  0.76600552,  0.77593643,  0.77523711,\n",
       "         0.77666418,  0.77975761,  0.77763589,  0.77386518,  0.79226123,\n",
       "         0.78602399,  0.79096614,  0.78903515,  0.79219925,  0.78850845,\n",
       "         0.78855777,  0.78734475,  0.79223916]),\n",
       " 'split1_train_score': array([ 0.73769357,  0.74242685,  0.73903281,  0.75412708,  0.75207539,\n",
       "         0.75270374,  0.76455249,  0.75863038,  0.75838171,  0.81307378,\n",
       "         0.81151653,  0.80692897,  0.82769896,  0.82615746,  0.8217492 ,\n",
       "         0.83207969,  0.83248475,  0.83104303,  0.84123736,  0.84519554,\n",
       "         0.84393317,  0.85679606,  0.85883154,  0.85598425,  0.86470046,\n",
       "         0.86324985,  0.8613104 ,  0.73904542,  0.73929176,  0.73967468,\n",
       "         0.75169164,  0.75000442,  0.75204938,  0.75888227,  0.75978869,\n",
       "         0.75721013,  0.82233434,  0.82170114,  0.81974555,  0.83987732,\n",
       "         0.83963853,  0.83707152,  0.84697883,  0.84990216,  0.84543668,\n",
       "         0.86542981,  0.86651162,  0.86724148,  0.88138394,  0.8840864 ,\n",
       "         0.87996859,  0.8908793 ,  0.88899001,  0.88952825,  0.74061113,\n",
       "         0.73584919,  0.73722898,  0.75108777,  0.75424102,  0.75618757,\n",
       "         0.75726652,  0.75606268,  0.75995238,  0.82521533,  0.82503135,\n",
       "         0.82338635,  0.84342362,  0.84200612,  0.84061678,  0.85112281,\n",
       "         0.85254283,  0.84988872,  0.87662884,  0.87879126,  0.8764619 ,\n",
       "         0.89495239,  0.89364051,  0.89556892,  0.90436986,  0.90531423,\n",
       "         0.9028321 ,  0.73564159,  0.73711426,  0.73878064,  0.75553412,\n",
       "         0.75511878,  0.75342838,  0.75821371,  0.75908241,  0.75786072,\n",
       "         0.82775141,  0.82678335,  0.82077294,  0.84366876,  0.84443457,\n",
       "         0.83801283,  0.85084273,  0.85231095,  0.84957724,  0.87906132,\n",
       "         0.88066135,  0.87990959,  0.89960957,  0.9004519 ,  0.89749485,\n",
       "         0.91081432,  0.90686935,  0.9092942 ]),\n",
       " 'split2_test_score': array([ 0.73966703,  0.74055363,  0.73735311,  0.75039734,  0.75466684,\n",
       "         0.7494549 ,  0.75278768,  0.75052611,  0.74810865,  0.78341881,\n",
       "         0.78835405,  0.78298955,  0.79127911,  0.79201395,  0.79093024,\n",
       "         0.79160916,  0.79134999,  0.79936535,  0.81360855,  0.8012697 ,\n",
       "         0.79966811,  0.81267252,  0.80883668,  0.80729888,  0.82144766,\n",
       "         0.8140744 ,  0.81317467,  0.73849673,  0.74191512,  0.73709801,\n",
       "         0.75134862,  0.74311877,  0.75180733,  0.75094241,  0.75254442,\n",
       "         0.74929301,  0.79248741,  0.78655457,  0.78651341,  0.78912538,\n",
       "         0.78706029,  0.78652793,  0.7966923 ,  0.79275192,  0.79300543,\n",
       "         0.80628584,  0.81036682,  0.80305722,  0.80978246,  0.8100232 ,\n",
       "         0.80676353,  0.81659874,  0.80484203,  0.81453655,  0.73942082,\n",
       "         0.74054108,  0.74078839,  0.74588366,  0.74800832,  0.75035997,\n",
       "         0.7505686 ,  0.75756047,  0.75489637,  0.78571341,  0.78807621,\n",
       "         0.78509469,  0.79957159,  0.78999959,  0.78988764,  0.78737088,\n",
       "         0.79306296,  0.79321596,  0.80481676,  0.81191106,  0.80126638,\n",
       "         0.80778397,  0.80747156,  0.80519781,  0.81512166,  0.80563987,\n",
       "         0.80978361,  0.74561036,  0.73886333,  0.7404104 ,  0.74891227,\n",
       "         0.75409379,  0.74869714,  0.75203416,  0.74851918,  0.75431668,\n",
       "         0.78430062,  0.78444427,  0.78548034,  0.79443738,  0.79366696,\n",
       "         0.79215515,  0.79389832,  0.79222823,  0.78820055,  0.80859244,\n",
       "         0.80940372,  0.8129727 ,  0.81263344,  0.80614826,  0.81119595,\n",
       "         0.80600814,  0.8164669 ,  0.80781458]),\n",
       " 'split2_train_score': array([ 0.73137303,  0.73369615,  0.73327701,  0.74626296,  0.74796714,\n",
       "         0.74678954,  0.75198955,  0.75165726,  0.75021695,  0.79908965,\n",
       "         0.79997147,  0.79773965,  0.81313612,  0.81055941,  0.81089543,\n",
       "         0.82013803,  0.8227035 ,  0.81795437,  0.83023563,  0.82746412,\n",
       "         0.82936603,  0.84185949,  0.84422156,  0.83909064,  0.85366903,\n",
       "         0.85197048,  0.84799311,  0.73486891,  0.73302292,  0.73133811,\n",
       "         0.74878975,  0.74350602,  0.74450064,  0.75105076,  0.75164988,\n",
       "         0.75202699,  0.81388382,  0.8134365 ,  0.81267063,  0.82963936,\n",
       "         0.83039404,  0.82730319,  0.83605294,  0.83471856,  0.83408349,\n",
       "         0.85928038,  0.85750762,  0.85440021,  0.86946812,  0.87018426,\n",
       "         0.87080888,  0.88119149,  0.87878501,  0.8777206 ,  0.73389188,\n",
       "         0.73582374,  0.73168184,  0.74240698,  0.74104473,  0.74629832,\n",
       "         0.75060581,  0.75563128,  0.75182264,  0.81522035,  0.81517552,\n",
       "         0.810416  ,  0.83234147,  0.83041101,  0.82725452,  0.8368252 ,\n",
       "         0.83903686,  0.83838071,  0.87222846,  0.86963972,  0.86711657,\n",
       "         0.88250685,  0.88585005,  0.88243787,  0.89309549,  0.89570716,\n",
       "         0.89157945,  0.73464142,  0.73544251,  0.73605181,  0.74584513,\n",
       "         0.74758095,  0.74522047,  0.7518961 ,  0.7533554 ,  0.75467959,\n",
       "         0.81334032,  0.8151098 ,  0.81244559,  0.83051747,  0.83061188,\n",
       "         0.82788889,  0.83999293,  0.84222448,  0.83749889,  0.87375297,\n",
       "         0.87132567,  0.87160404,  0.89649075,  0.8905833 ,  0.88835776,\n",
       "         0.90135193,  0.90226148,  0.8990269 ]),\n",
       " 'std_fit_time': array([ 0.00338457,  0.0009488 ,  0.00170382,  0.01315835,  0.0028293 ,\n",
       "         0.00219781,  0.00513764,  0.00088025,  0.00477241,  0.00140145,\n",
       "         0.00028379,  0.00254897,  0.00110921,  0.00456828,  0.00348399,\n",
       "         0.00352914,  0.00932179,  0.0009958 ,  0.00540319,  0.00553543,\n",
       "         0.00518029,  0.08862848,  0.06979487,  0.04883456,  0.01701663,\n",
       "         0.00304791,  0.00651833,  0.00423761,  0.0037574 ,  0.00359042,\n",
       "         0.01079056,  0.00522035,  0.0091513 ,  0.00518095,  0.00545849,\n",
       "         0.00376381,  0.0050321 ,  0.02320228,  0.01291443,  0.00284673,\n",
       "         0.00930723,  0.00419739,  0.00548822,  0.00630711,  0.0138098 ,\n",
       "         0.00289866,  0.00181442,  0.00416804,  0.00282979,  0.00456949,\n",
       "         0.00928418,  0.00475686,  0.00493782,  0.00652478,  0.00139413,\n",
       "         0.00285872,  0.00470741,  0.05010607,  0.01428158,  0.01225199,\n",
       "         0.00581776,  0.01757503,  0.00385044,  0.00439951,  0.00272171,\n",
       "         0.00185241,  0.00396581,  0.00205563,  0.00068609,  0.00315733,\n",
       "         0.00812222,  0.00201777,  0.00538236,  0.006476  ,  0.00785704,\n",
       "         0.00554701,  0.00695081,  0.00568423,  0.00658096,  0.00155183,\n",
       "         0.00510071,  0.00158157,  0.00625434,  0.0011884 ,  0.0027978 ,\n",
       "         0.00671993,  0.0036393 ,  0.04645173,  0.0185119 ,  0.01272043,\n",
       "         0.00571187,  0.00210374,  0.02407545,  0.01755264,  0.00595993,\n",
       "         0.01752316,  0.02909095,  0.00878546,  0.02670807,  0.02746722,\n",
       "         0.04679801,  0.04032973,  0.04569015,  0.02595627,  0.01096508,\n",
       "         0.03247709,  0.01297969,  0.00540628]),\n",
       " 'std_score_time': array([  3.80380403e-04,   7.35361473e-05,   8.46060913e-05,\n",
       "          2.47574962e-04,   2.92961518e-04,   1.25557410e-04,\n",
       "          1.88324554e-04,   8.58353243e-05,   2.40600011e-04,\n",
       "          2.11702005e-04,   1.92994796e-04,   1.95120991e-03,\n",
       "          3.09004971e-04,   2.99642803e-04,   1.27270618e-04,\n",
       "          3.69373625e-04,   3.66658527e-05,   4.47026182e-05,\n",
       "          1.18926879e-04,   9.45413762e-05,   1.58517630e-03,\n",
       "          1.20868217e-03,   5.57411058e-04,   5.06727978e-04,\n",
       "          3.55164788e-04,   3.01546129e-04,   1.76006352e-04,\n",
       "          1.65617741e-04,   1.10090595e-04,   1.33180769e-04,\n",
       "          2.19203753e-04,   6.20370732e-04,   2.22970056e-04,\n",
       "          2.63624713e-04,   1.90949154e-04,   2.17170346e-04,\n",
       "          1.71931703e-04,   1.71275304e-03,   1.41743303e-03,\n",
       "          5.49426510e-04,   1.19072571e-04,   1.69812209e-04,\n",
       "          2.84340543e-04,   2.60666715e-04,   4.36909894e-04,\n",
       "          2.11342796e-04,   1.60043620e-04,   2.40564937e-04,\n",
       "          2.20970882e-04,   3.42660190e-04,   1.44812723e-04,\n",
       "          1.53681196e-04,   4.36863575e-04,   9.78121402e-05,\n",
       "          1.61057275e-04,   4.39813763e-04,   4.00894647e-04,\n",
       "          3.37240044e-04,   1.67493007e-03,   1.95130844e-04,\n",
       "          3.34431973e-04,   1.11039148e-03,   1.25972480e-04,\n",
       "          4.18481773e-05,   1.67480185e-04,   3.02036601e-05,\n",
       "          3.47475483e-05,   1.23922815e-03,   3.54214931e-04,\n",
       "          3.55906210e-04,   4.32130282e-04,   3.13516795e-04,\n",
       "          2.05874777e-04,   4.64750991e-04,   2.62351839e-04,\n",
       "          5.76164530e-06,   6.00474388e-04,   1.27016367e-03,\n",
       "          5.66825028e-04,   9.34122925e-05,   3.05162556e-04,\n",
       "          2.41021963e-04,   2.15846678e-04,   2.75048047e-04,\n",
       "          1.08499985e-04,   3.06458703e-04,   2.80733667e-04,\n",
       "          2.81880027e-04,   6.32570885e-04,   3.03241628e-04,\n",
       "          4.00715320e-04,   4.34225291e-04,   5.72547854e-04,\n",
       "          3.04783401e-04,   2.19475004e-04,   3.32594649e-04,\n",
       "          6.55632568e-04,   6.63372475e-04,   9.54513049e-05,\n",
       "          9.23363142e-05,   4.66913177e-03,   7.00066646e-04,\n",
       "          5.55843675e-03,   1.32792138e-03,   1.77534293e-04,\n",
       "          2.68078031e-03,   7.28071926e-04,   1.25482990e-04]),\n",
       " 'std_test_score': array([ 0.02505439,  0.02335413,  0.02501724,  0.02738895,  0.03061685,\n",
       "         0.02730205,  0.03011401,  0.03047576,  0.02921346,  0.02337628,\n",
       "         0.022918  ,  0.02273334,  0.02059041,  0.0227089 ,  0.0239412 ,\n",
       "         0.0186376 ,  0.02127763,  0.02456252,  0.03121643,  0.02270434,\n",
       "         0.02112968,  0.02576067,  0.02303063,  0.02433552,  0.02819802,\n",
       "         0.02458167,  0.0263241 ,  0.02862708,  0.0244317 ,  0.02525026,\n",
       "         0.02902732,  0.02511843,  0.03290756,  0.02730172,  0.02963458,\n",
       "         0.02880836,  0.02144702,  0.02184298,  0.02303776,  0.02342027,\n",
       "         0.02076131,  0.02033473,  0.02383075,  0.02228153,  0.02322595,\n",
       "         0.02267655,  0.02428732,  0.02269402,  0.02451978,  0.02396736,\n",
       "         0.02252139,  0.02242465,  0.02102358,  0.02514643,  0.0270914 ,\n",
       "         0.0266393 ,  0.02626902,  0.02609681,  0.02854176,  0.02960717,\n",
       "         0.02750479,  0.03227781,  0.03028391,  0.02031369,  0.01978736,\n",
       "         0.02344074,  0.02373902,  0.02219282,  0.02627335,  0.01832794,\n",
       "         0.02361959,  0.01919912,  0.01984741,  0.02659073,  0.02090416,\n",
       "         0.02175452,  0.01959717,  0.02210217,  0.03167289,  0.02335611,\n",
       "         0.0247467 ,  0.0290986 ,  0.02597851,  0.02792064,  0.02896389,\n",
       "         0.03073049,  0.02826548,  0.0311755 ,  0.02717822,  0.03036179,\n",
       "         0.01740508,  0.02160356,  0.02039315,  0.02222664,  0.02352114,\n",
       "         0.02072113,  0.02059494,  0.02285052,  0.02098444,  0.02479094,\n",
       "         0.02462516,  0.02586952,  0.02529957,  0.0244951 ,  0.02757734,\n",
       "         0.02418086,  0.02608962,  0.02519334]),\n",
       " 'std_train_score': array([ 0.01277819,  0.01297162,  0.01124635,  0.01172167,  0.01247499,\n",
       "         0.01142671,  0.0119316 ,  0.01248105,  0.01289198,  0.00944307,\n",
       "         0.00917805,  0.00974165,  0.00946153,  0.00924254,  0.00972677,\n",
       "         0.00817375,  0.00844298,  0.00979061,  0.00896897,  0.01218392,\n",
       "         0.00973582,  0.01040276,  0.00886628,  0.01048439,  0.00902017,\n",
       "         0.00835839,  0.00977337,  0.0102576 ,  0.01376051,  0.01234943,\n",
       "         0.01127542,  0.01539214,  0.01216486,  0.01379077,  0.01296424,\n",
       "         0.01256224,  0.00857102,  0.00855845,  0.00923032,  0.00798542,\n",
       "         0.00873334,  0.0081208 ,  0.00959662,  0.00949063,  0.0088275 ,\n",
       "         0.00757593,  0.00853541,  0.00841912,  0.01171142,  0.00896982,\n",
       "         0.00831319,  0.00836659,  0.00935178,  0.00813424,  0.01271777,\n",
       "         0.01034167,  0.012693  ,  0.01424543,  0.01454296,  0.01188641,\n",
       "         0.01437813,  0.01367033,  0.01286734,  0.00951954,  0.00930201,\n",
       "         0.01055331,  0.00808944,  0.00949373,  0.00999481,  0.0095518 ,\n",
       "         0.00876938,  0.00784516,  0.00731995,  0.0080586 ,  0.00727567,\n",
       "         0.00878307,  0.00881363,  0.00913317,  0.00841975,  0.00754021,\n",
       "         0.0086958 ,  0.01282928,  0.01114195,  0.00839947,  0.01205593,\n",
       "         0.01070678,  0.0128363 ,  0.01221093,  0.01441714,  0.01170172,\n",
       "         0.00962499,  0.00797376,  0.01013283,  0.00841697,  0.00920343,\n",
       "         0.00946813,  0.00677244,  0.00655768,  0.00816366,  0.00861706,\n",
       "         0.00881662,  0.00864438,  0.00439595,  0.00728449,  0.00895041,\n",
       "         0.00728237,  0.00654   ,  0.00760656])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.05,\n",
       "             n_estimators=120, presort='auto', random_state=None,\n",
       "             subsample=0.6, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Selección\n",
    "\n",
    "Genial, ya sabemos que parametros hemos de coger y que son lo más optimos en este caso, veamos que se obtiene ahora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14901905  0.13464619  0.12518018  0.15877724  0.13403575  0.14804185\n",
      "  0.13385177  0.12829163  0.13793748  0.12125371]\n",
      "[ 0.67796801  0.79787778  0.76286809  0.69742384  0.81480704  0.75726779\n",
      "  0.78034657  0.80347735  0.77701473  0.82469473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor(n_estimators= 100, max_depth=5, subsample= 0.7\n",
    "                                      ,min_weight_fraction_leaf=0.1)\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'), cv=10)\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y en este caso el error es: \n",
      "0.11875604746\n"
     ]
    }
   ],
   "source": [
    "#Error cometido en esta medicion MAE \n",
    "prediccion = clf.predict(X_test)\n",
    "print(\"y en este caso el error es: \")\n",
    "print (mean_absolute_error(y_test,prediccion ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKhiGPiJiCrm/wPjr4jgzGw50gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3413f1ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamoslo en un scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(prediccion, y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
