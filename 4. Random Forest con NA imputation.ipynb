{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random forest\n",
    "\n",
    "Realicemos una predicción basada en un random forest. \n",
    "Se parte de los datos analizados, normalizados y acotados logrados en el punto 0, para el training.\n",
    "\n",
    "Este método se basa en hacer una media de la predicción obtenida con  muchos decision trees y aún sin ajustes, suele funcionar bien.\n",
    "\n",
    "Partiendo de una contrucción del modelo, haremos un proceso iterativo de validación y ajuste del mismo (modificando parámetros y variables), hasta obtener el que mejor predice nuestra target, sin infra o sobreajustes\n",
    "\n",
    "## Importación de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.805765</td>\n",
       "      <td>729.805765</td>\n",
       "      <td>56.877145</td>\n",
       "      <td>10460.434454</td>\n",
       "      <td>6.094715</td>\n",
       "      <td>5.576527</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1984.818806</td>\n",
       "      <td>439.128346</td>\n",
       "      <td>46.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.069321</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.402158</td>\n",
       "      <td>421.402158</td>\n",
       "      <td>42.339638</td>\n",
       "      <td>9862.564977</td>\n",
       "      <td>1.376542</td>\n",
       "      <td>1.113638</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>20.640669</td>\n",
       "      <td>432.964939</td>\n",
       "      <td>161.471529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.090410</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.383022</td>\n",
       "      <td>0.278112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>364.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9473.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2188.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           Id   MSSubClass        LotArea  OverallQual  \\\n",
       "count  1457.000000  1457.000000  1457.000000    1457.000000  1457.000000   \n",
       "mean    728.805765   729.805765    56.877145   10460.434454     6.094715   \n",
       "std     421.402158   421.402158    42.339638    9862.564977     1.376542   \n",
       "min       0.000000     1.000000    20.000000    1300.000000     1.000000   \n",
       "25%     364.000000   365.000000    20.000000    7540.000000     5.000000   \n",
       "50%     729.000000   730.000000    50.000000    9473.000000     6.000000   \n",
       "75%    1093.000000  1094.000000    70.000000   11600.000000     7.000000   \n",
       "max    1459.000000  1460.000000   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1457.000000  1457.000000   1457.000000  1457.000000  1457.000000   \n",
       "mean      5.576527  1971.194235   1984.818806   439.128346    46.645161   \n",
       "std       1.113638    30.190353     20.640669   432.964939   161.471529   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1972.000000   1994.000000   383.000000     0.000000   \n",
       "75%       6.000000  2000.000000   2004.000000   712.000000     0.000000   \n",
       "max       9.000000  2010.000000   2010.000000  2188.000000  1474.000000   \n",
       "\n",
       "               ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "count          ...               1457.000000   1457.000000   1457.000000   \n",
       "mean           ...                  0.003432      0.082361      0.002059   \n",
       "std            ...                  0.058500      0.275008      0.045345   \n",
       "min            ...                  0.000000      0.000000      0.000000   \n",
       "25%            ...                  0.000000      0.000000      0.000000   \n",
       "50%            ...                  0.000000      0.000000      0.000000   \n",
       "75%            ...                  0.000000      0.000000      0.000000   \n",
       "max            ...                  1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "count  1457.000000            1457.000000            1457.000000   \n",
       "mean      0.868909               0.069321               0.002745   \n",
       "std       0.337616               0.254086               0.052342   \n",
       "min       0.000000               0.000000               0.000000   \n",
       "25%       1.000000               0.000000               0.000000   \n",
       "50%       1.000000               0.000000               0.000000   \n",
       "75%       1.000000               0.000000               0.000000   \n",
       "max       1.000000               1.000000               1.000000   \n",
       "\n",
       "       SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "count           1457.000000           1457.000000           1457.000000   \n",
       "mean               0.008236              0.013727              0.821551   \n",
       "std                0.090410              0.116395              0.383022   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              1.000000   \n",
       "50%                0.000000              0.000000              1.000000   \n",
       "75%                0.000000              0.000000              1.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Partial  \n",
       "count            1457.000000  \n",
       "mean                0.084420  \n",
       "std                 0.278112  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 223 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerías a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importación de datos\n",
    "melbourne_data = pd.read_csv(\"data/PreciosCasas/train_final.csv\", sep='\\t', encoding='utf-8') \n",
    "\n",
    "# print a summary of the data in Melbourne data\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=223)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos\n",
    "\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos prededir el precio, será nuestro target, para lo cual, cogeremos unas variables como pedictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10460.434454</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1159.129032</td>\n",
       "      <td>345.560055</td>\n",
       "      <td>1.563487</td>\n",
       "      <td>2.866163</td>\n",
       "      <td>6.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9862.564977</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>372.015864</td>\n",
       "      <td>435.505117</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.816595</td>\n",
       "      <td>1.616384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7540.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9473.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11600.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3228.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1457.000000  1457.000000  1457.000000  1457.000000  1457.000000   \n",
       "mean    10460.434454  1971.194235  1159.129032   345.560055     1.563487   \n",
       "std      9862.564977    30.190353   372.015864   435.505117     0.549961   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7540.000000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9473.000000  1972.000000  1086.000000     0.000000     2.000000   \n",
       "75%     11600.000000  2000.000000  1391.000000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  3228.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1457.000000   1457.000000  \n",
       "mean       2.866163      6.510638  \n",
       "std        0.816595      1.616384  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= melbourne_data.SalePrice\n",
    "print(y.head())\n",
    "melbourne_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = melbourne_data[melbourne_predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del modelo **Random Forest**\n",
    "\n",
    "El Random forest, usa muchos trees, y hace una predicción media de cada tree componente. En general, ajusta mejor que un arrbol de decisión simple y funciona bien hasta con los parámetros base.\n",
    "\n",
    "Para ser capaces de ir validando el modelo, lo separaremos en dos grupos, predictors and target. Lo haremos mediando un split con un número generaro aleatorio. Como queremos que todas las veces que ejecutemos el modelo nos salga lo mismo, estableceremos el argumento de random_state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "from  sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "#Separamos los datos en dos grupos, \n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.134657777236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJB2dpvIQy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a5239fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamoslo en un scatter plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(melb_preds,val_y);\n",
    "plt.title('Validación');\n",
    "plt.ylabel('Modelo');\n",
    "plt.xlabel('Prediccion');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejora del modelo\n",
    "\n",
    "Vamos a probar seleccionando otras variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Mean Absolute Error from dropping columns with Missing Values:\n",
      "0.096529455609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#1) Limpiar datos, borrando valores perdidos\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "melb_data= melbourne_data\n",
    "melb_target = melbourne_data.SalePrice\n",
    "melb_predictors = melbourne_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# For the sake of keeping the example simple, we'll use only numeric predictors. \n",
    "melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "\n",
    "#funcion para calcular MAE\n",
    "X_train, X_test, y_train, y_test = train_test_split(melb_numeric_predictors, \n",
    "                                                    melb_target,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor(n_estimators=60, max_depth=10, min_samples_split=10, random_state=29011982)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "cols_with_missing = [col for col in X_train.columns \n",
    "                                 if X_train[col].isnull().any()]\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test  = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print (cols_with_missing)\n",
    "print(\"Mean Absolute Error from dropping columns with Missing Values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2',\n",
       "       ...\n",
       "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleCondition_Partial'],\n",
       "      dtype='object', length=222)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de imputación \n",
    "Para trabajar con los datos vacíos hay varias opciones:\n",
    "   - Eliminamos esas columnas (y perdemos datos, claro)\n",
    "   - Hacemos imputaciones: ponermos un valor medio en esos \"huecos\" vacíos\n",
    "   - Hacemos una imputación pero añadiendo además una columna que especifique que valores son reales, y cuales imputados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "0.096529455609\n"
     ]
    }
   ],
   "source": [
    "# Imputation\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "#print(pd.DataFrame(imputed_X_train).sample (5))\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, numpy.ndarray)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(imputed_X_train)  # como son tipos distintos no aplican las mismas propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while Track What Was Imputed:\n",
      "0.096529455609\n"
     ]
    }
   ],
   "source": [
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns \n",
    "                                 if X_train[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
