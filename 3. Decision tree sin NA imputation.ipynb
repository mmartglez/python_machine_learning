{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree\n",
    "\n",
    "Realicemos una predicción basada en un random forest. \n",
    "Se parte de los datos analizados, normalizados y acotados logrados en el punto 0, para el training.\n",
    "\n",
    "Este método se basa en hacer varios decision trees. Veremos que necesita ajustes y no suele ser el mejor método para overfitting.\n",
    "\n",
    "Partiendo de una contrucción del modelo, haremos un proceso iterativo de validación y ajuste del mismo (modificando parámetros y variables), hasta obtener el que mejor predice nuestra target, sin infra o sobreajustes\n",
    "\n",
    "## Importación de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.805765</td>\n",
       "      <td>729.805765</td>\n",
       "      <td>56.877145</td>\n",
       "      <td>10460.434454</td>\n",
       "      <td>6.094715</td>\n",
       "      <td>5.576527</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1984.818806</td>\n",
       "      <td>439.128346</td>\n",
       "      <td>46.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.069321</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.402158</td>\n",
       "      <td>421.402158</td>\n",
       "      <td>42.339638</td>\n",
       "      <td>9862.564977</td>\n",
       "      <td>1.376542</td>\n",
       "      <td>1.113638</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>20.640669</td>\n",
       "      <td>432.964939</td>\n",
       "      <td>161.471529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.090410</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.383022</td>\n",
       "      <td>0.278112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>364.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9473.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2188.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           Id   MSSubClass        LotArea  OverallQual  \\\n",
       "count  1457.000000  1457.000000  1457.000000    1457.000000  1457.000000   \n",
       "mean    728.805765   729.805765    56.877145   10460.434454     6.094715   \n",
       "std     421.402158   421.402158    42.339638    9862.564977     1.376542   \n",
       "min       0.000000     1.000000    20.000000    1300.000000     1.000000   \n",
       "25%     364.000000   365.000000    20.000000    7540.000000     5.000000   \n",
       "50%     729.000000   730.000000    50.000000    9473.000000     6.000000   \n",
       "75%    1093.000000  1094.000000    70.000000   11600.000000     7.000000   \n",
       "max    1459.000000  1460.000000   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1457.000000  1457.000000   1457.000000  1457.000000  1457.000000   \n",
       "mean      5.576527  1971.194235   1984.818806   439.128346    46.645161   \n",
       "std       1.113638    30.190353     20.640669   432.964939   161.471529   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1972.000000   1994.000000   383.000000     0.000000   \n",
       "75%       6.000000  2000.000000   2004.000000   712.000000     0.000000   \n",
       "max       9.000000  2010.000000   2010.000000  2188.000000  1474.000000   \n",
       "\n",
       "               ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "count          ...               1457.000000   1457.000000   1457.000000   \n",
       "mean           ...                  0.003432      0.082361      0.002059   \n",
       "std            ...                  0.058500      0.275008      0.045345   \n",
       "min            ...                  0.000000      0.000000      0.000000   \n",
       "25%            ...                  0.000000      0.000000      0.000000   \n",
       "50%            ...                  0.000000      0.000000      0.000000   \n",
       "75%            ...                  0.000000      0.000000      0.000000   \n",
       "max            ...                  1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "count  1457.000000            1457.000000            1457.000000   \n",
       "mean      0.868909               0.069321               0.002745   \n",
       "std       0.337616               0.254086               0.052342   \n",
       "min       0.000000               0.000000               0.000000   \n",
       "25%       1.000000               0.000000               0.000000   \n",
       "50%       1.000000               0.000000               0.000000   \n",
       "75%       1.000000               0.000000               0.000000   \n",
       "max       1.000000               1.000000               1.000000   \n",
       "\n",
       "       SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "count           1457.000000           1457.000000           1457.000000   \n",
       "mean               0.008236              0.013727              0.821551   \n",
       "std                0.090410              0.116395              0.383022   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              1.000000   \n",
       "50%                0.000000              0.000000              1.000000   \n",
       "75%                0.000000              0.000000              1.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Partial  \n",
       "count            1457.000000  \n",
       "mean                0.084420  \n",
       "std                 0.278112  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 222 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerías a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importación de datos\n",
    "melbourne_data = pd.read_csv(\"data/PreciosCasas/train_final.csv\", sep='\\t', encoding='utf-8') \n",
    "\n",
    "# print a summary of the data in Melbourne data\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=222)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos\n",
    "\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos prededir el precio, será nuestro target, para lo cual, cogeremos unas variables como pedictores ( de momento, las que vemos que probablemente mejor predicen la target, y en el proceso de iteración es cuando vamos verficándolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10460.434454</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1159.129032</td>\n",
       "      <td>345.560055</td>\n",
       "      <td>1.563487</td>\n",
       "      <td>2.866163</td>\n",
       "      <td>6.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9862.564977</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>372.015864</td>\n",
       "      <td>435.505117</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.816595</td>\n",
       "      <td>1.616384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7540.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9473.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11600.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3228.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1457.000000  1457.000000  1457.000000  1457.000000  1457.000000   \n",
       "mean    10460.434454  1971.194235  1159.129032   345.560055     1.563487   \n",
       "std      9862.564977    30.190353   372.015864   435.505117     0.549961   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7540.000000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9473.000000  1972.000000  1086.000000     0.000000     2.000000   \n",
       "75%     11600.000000  2000.000000  1391.000000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  3228.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1457.000000   1457.000000  \n",
       "mean       2.866163      6.510638  \n",
       "std        0.816595      1.616384  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= melbourne_data.SalePrice\n",
    "print(y.head())\n",
    "melbourne_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = melbourne_data[melbourne_predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del modelo Decision Tree models\n",
    "\n",
    "El modelo que vamos a hacer es scikit-learn, y luego validamos que tal es mediante Mean Absolute Error (MAE). El error de predicción será: error= valor actual−predicción\n",
    "\n",
    "Para ser capaces de ir validando el modelo, lo separaremos en dos grupos, predictors and target. Lo haremos mediando un split con un número generaro aleatorio. Como queremos que todas las veces que ejecutemos el modelo nos salga lo mismo, estableceremos el argumento de random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "from  sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Separamos los datos en dos grupos, \n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Por qué hacemos esa separación del df en dos grupos?**\n",
    "\n",
    "En este punto, solo por practicar, veamos que pasa tanto si realizo esa separación como si no la hago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_training= test. Predicciones de estas casas: \n",
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "0     8450       2003       856       854         2             3   \n",
      "1     9600       1976      1262         0         2             3   \n",
      "2    11250       2001       920       866         2             3   \n",
      "3     9550       1915       961       756         1             3   \n",
      "4    14260       2000      1145      1053         2             4   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "0             8  \n",
      "1             6  \n",
      "2             6  \n",
      "3             7  \n",
      "4             9  \n",
      "La predictions \n",
      "[ 12.24769432  12.10901093  12.31716669  11.8493977   12.4292162 ]\n",
      "y el real es\n",
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: SalePrice, dtype: float64\n",
      "error para el conjunto de training es: \n",
      "0.000492273525725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1_ Si no cogieramos el training y validación: Hacemos el modelo\n",
    "melbourne_model= DecisionTreeRegressor()\n",
    "melbourne_model.fit(X,y)\n",
    "\n",
    "#Veamos como funciona\n",
    "print(\"1_training= test. Predicciones de estas casas: \")\n",
    "print(X.head())\n",
    "print(\"La predictions \")\n",
    "print(melbourne_model.predict(X.head()))\n",
    "print(\"y el real es\")\n",
    "print(y.head())\n",
    "\n",
    "val_predicted_home_prices = melbourne_model.predict(X)\n",
    "print(\"error para el conjunto de training es: \")\n",
    "print (mean_absolute_error(y,val_predicted_home_prices ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aqui tengo el problema!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f684dc5fce21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Veamoslo en un scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predicted_home_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3434\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3435\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3962\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3964\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3966\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    }
   ],
   "source": [
    "# Veamoslo en un scatter plot\n",
    "plt.scatter(val_predicted_home_prices, y );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_ Training<> Test. Predicciones de estas casas:\n",
      "     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "411    34650       1955      1056         0         1             3   \n",
      "211    10420       2009      1212         0         2             3   \n",
      "342     8544       1949      1040         0         2             2   \n",
      "303     9800       1972       894         0         1             3   \n",
      "159    19378       2005      1392      1070         2             4   \n",
      "\n",
      "     TotRmsAbvGrd  \n",
      "411             5  \n",
      "211             6  \n",
      "342             6  \n",
      "303             5  \n",
      "159             9  \n",
      "The predictions are\n",
      "[ 12.10071213  12.20055746  11.44249782  11.77528973  12.77705219]\n",
      "And the real is\n",
      "411    11.884489\n",
      "211    12.133502\n",
      "342    11.379394\n",
      "303    11.917724\n",
      "159    12.676076\n",
      "Name: SalePrice, dtype: float64\n",
      "y en este caso el error es: \n",
      "0.169929723949\n"
     ]
    }
   ],
   "source": [
    "#2_ Si cogemos el training y validación: Hacemos el modelo\n",
    "melbourne_model= DecisionTreeRegressor()\n",
    "melbourne_model.fit(train_X,train_y)\n",
    "\n",
    "#Veamos como funciona\n",
    "print(\"2_ Training<> Test. Predicciones de estas casas:\")\n",
    "print(val_X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(val_X.head()))\n",
    "print(\"And the real is\")\n",
    "print(val_y.head())\n",
    "\n",
    "#Error cometido en esta medicion MAE \n",
    "val_predicted_home_prices2 = melbourne_model.predict(val_X)\n",
    "print(\"y en este caso el error es: \")\n",
    "print (mean_absolute_error(val_y,val_predicted_home_prices2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+MXeV5J/DvM9fXzh2XzZhliuLLz66QvRBie5mydKmi\n2JUwv5liCEGs1DRRUaXSVVDkrFmiYFKqODvqttUmUsqmiFZxiUkMs6aQ2mTxCsmK24w1NuBit4QA\n9iUbT2SGBGbAd2ae/WPuGZ85c95z3vPj3vPr+5EQM9f3xzn32M8553mf93lFVUFERNXRl/UGEBFR\nbzHwExFVDAM/EVHFMPATEVUMAz8RUcUw8BMRVQwDPxFRxTDwExFVDAM/EVHFLMt6A/ycd955eskl\nl2S9GUREhXHo0KFfqOqgzXNzGfgvueQSjI2NZb0ZRESFISJv2j6XqR4iooph4CciqhgGfiKiimHg\nJyKqGAZ+IqKKYeAnIqqYXJZzEhFVxeh4CyN7j+PtyWmsHmhg6+Y1GN7Q7OpnMvATEWVkdLyFB556\nGdPtWQBAa3IaDzz1MgB0Nfgz1UNElJGRvccXgr5juj2Lkb3Hu/q5DPxERBl5e3I60uNpYeAnIsrI\n6oFGpMfTwsBPRJSRrZvXoFGvLXqsUa9h6+Y1Xf1cDu4SEWXEGcBlVQ8RUYUMb2h2PdB7MfATEWWI\ndfxERBXCOn4ioophHT8RUcWwjp+IqGJYx09EVDGs4yciqhjW8RMRVVAWdfxM9RARVQwDPxFRxTDw\nExFVDAM/EVHFMPATEVUMAz8RUcWwnJOIKGVZdNyMgoGfiChFWXXcjIKpHiKiFGXVcTMKXvETEQWI\nmrbJquNmFKGBX0QeA3AzgFOq+vHOY38C4DYAcwBOAfisqr7t89rrAfwlgBqAb6vqjhS3nYgoVd4g\nv3HtIHYfakVK26weaKDlE+S73XEzCptUz+MArvc8NqKqn1DV9QD+HsBXvC8SkRqAbwK4AcDlAO4W\nkcuTbS4RUXc4ufnW5DQU80F+58G3Iqdt/DpuCoCNawe7sNXxhAZ+VX0RwGnPY790/boSgPq89GoA\nr6nq66p6BsB3MX+XQESUO365eb/ABgSnbYY3NLHlqibE8z67D7UwOt5KvJ1piD24KyJ/KiInANwD\nnyt+AE0AJ1y/n+w8RkSUO1Fy8GFpm/3HJpacNPI0wBs78Kvqg6p6IYCdAO5LuiEicq+IjInI2MTE\nRNK3IyKKxBTMxfO7zUIpeR/gTaOccyeALT6PtwBc6Pr9gs5jvlT1UVUdUtWhwcH85MKIqBpMq2Hd\nc81FaA40IACaAw187fYrQ+vxs1pS0VaswC8il7l+vQ3AMZ+n/RjAZSJyqYgsB/AZAHvifB4RURKj\n4y1cu+MFXLrtWVy74wXfXPvwhia+dvuVS4L80MXnRv68rJZUtGVTzvkEgE8BOE9ETgJ4CMCNIrIG\n8+WcbwL4w85zV2O+bPNGVZ0RkfsA7MV8Oedjqnq0O7tBROQvykxa72pYcWfhZrWkoi1RNY1bZ2do\naEjHxsay3gwi6oJe97G5dscLvnX1zYEGDmzb1LXX9pqIHFLVIZvncuYuEfVMFn1skgy05n2QNi4G\nfqISyHs3SEdQH5tubW+SmbRJZ+Hm9biwSRtRwfnNOH3gqZdzM1nILYsr6CQDrUlem+fjwsBPVHBF\n6AbpiFPmaFORE8RUrWNz5e3Mwq3JfDV/TQRbrmpavdb2uCTdvziY6iEquCLlobduXrMoxw8EX0Gn\nNSbgrdaxNTrewu5DLcx2imBmVbH7UAtDF58b+n42xyWr3v284icquLxPFnKLevWd9d1Mks8f6K+H\nPp7V/vGKn6jgol5FZy3K1XfWdzNJPt9UKe9+PKv94xU/UcElyWHnXdZ3M0k+/93pdujjWe0fAz9R\nCQxvaOLAtk346Y6bcGDbplIEfSD71gdJPt8mqGe1fwz8RJRbWd/NJPl8m6Ce1f6xZQMRUZf0cgIX\nWzYQUSXlbaZs3DLSbmPgJ6LUZRGAs6qJLyLm+IkoVVm1Ksi65r9IeMVPRIGiXr1n0YhtdLzl20wN\nOFsTn7c0UJYY+InIKE76pNeTkpxtNFk90GAayIOpHiIyipM+6fWkJL9tdDjlk0wDLcbAT0RGca7e\nw+rX0+5GGbQtTk18GnchWXTR7BameojIKM5CJEHrzYalXOLk4U3b2BxoLLw2aD9sPrNsqSIGfqIc\nyOvAY9wGcKb69bCUS5zgarONpudsXDto9ZlpDFjn6Rgz1UOUsTyv1JR2S4GglEvcPLzNNpqes//Y\nhNVnJk0V5e0Y84qfKGNZlD9Gkebs06CUS5LgarONznOcK+/7dx2GqWGN9zOTrr2bt2PMK36ijGXd\ncz5NYQOgQQO/aVUDBW2D98rbxPuZWzevQb1PFj1W7xPrLpp5O8YM/EQZy7rnfFps0hlBa9im0aL4\ny6Mv4/5dh43bEFT6GfqZEvJ7gLwdYwZ+ooxl3XM+LTY5etMatqPjrcBcvU0p5eh4CzsPvrXkSt69\nDUFX2EFjGCN7j6M9u/id27NqPQ8gb8eYOX6ijAWVP+aZt0olrGUCEJ7r9svV25ZSjuw9HpqzDyr9\nPLBtk3Ffk6Zq8naMGfiJciCv7XtN/IKxAL6B153OiBNAbQdGg97D2Yatm9dg6/eOoD13dkttcvVJ\nB3eBfB1jpnqIKDK/YKxYmvb2pjPi5LptTxam9xBgcWCPkavPW6omKQZ+IorMFIwVCKynjxNAbU8W\nfu8tAO655qJFqZY4ufqsl4BMG1M9RLTAdnapKfXhXF2bAmJYrtvv88Nm5rpf89FGHR+p92Fyqu27\n/d2eK1AUXHOXqGTitgbw5u2B+QDrd2X75dGX8Z2Db/m+T9hAaZzPB+x6/wRtMwBcu+OFWIO7RcA1\nd4kqKkkzMdtBVKck0yTupKSgzz+wbVPk3j9+z4/be6hsQgO/iDwG4GYAp1T1453HRgDcAuAMgJ8A\n+H1VnfR57RsAfgVgFsCM7dmIiOJJ0hrANg0SNgnKLydvcxcSJw0T9TV5K6vMis0V/+MAvgHgb12P\nPQ/gAVWdEZGvA3gAwH81vH6jqv4i0VYS9VCeuihGlSSHbVuyGPReztWzN+/+yw/acCooW5PT2Pq9\nIwAW34V8tFHH5HQ79PPjbLNbmXL1cYVW9ajqiwBOex7bp6oznV8PArigC9tG1HN566IYVZLWALYV\nN6b3qoks5OPd3+Hk9Nmg72jPKbbvOQpg/jtf//A+36AfVmNftjLLXkmjnPNzAH5g+DMF8EMROSQi\n9wa9iYjcKyJjIjI2MTGRwmYRRVf0JfqSBELbkkXTZ/zZp9dheEPTqh8OMH9CcE60fkEfAH7tI8sC\nr879tnnLVfPbcOm2Z7Hhq/uw/uF9pVg1K01WVT0icgmAv3dy/K7HHwQwBOB29XkjEWmqaktEfh3z\n6aE/7txBBGJVD2Xl0m3P+s4+FQA/3XFTrzcnll6kqoI+w/Qd+mkGtHpwP8d2X/yqfNyc2cXNgqXw\nbPSkqkdEPov5Qd/f8Qv6AKCqrc7/T4nI0wCuBhAa+ImyksbU/Kz1Iocd9BlBfXvcVvXXQ8ceBFh4\nL5sKpbC7DSdQFX3pxKRipXpE5HoAXwJwq6pOGZ6zUkTOcX4GcB2AV+JuKFEvlCVnbNvNshuLh/t9\nh35UgYH+evBzPL+b0m7OvticcNzv9fAzR62fXyY25ZxPAPgUgPNE5CSAhzBfxbMCwPMy31f7oKr+\noYisBvBtVb0RwPkAnu78+TIAf6eq/9CVvSBKSRnK/Wxq+ePU+9umkNzfYVDztsnpNup9gnpNlrRR\nCOK9SwhL7wR5Z6q90BK6SkIDv6re7fPwXxue+zaAGzs/vw5gXaKtI8pA0cv9bGr5o9b7J5kYFhTS\n23OKgUYdv/pgZqFHfxhv2s12MNkkL0tc9hJn7hKVjE0tf9R6/ygniqhX4O8aKnr8+KXdki5fGPT6\nIs/pCMLAT1QyNgPUUQexTcGxNTmNa3e8sCgwRr0CXz3QwNSZGbwztfQEMNCoY+WKZYGB13YwOejz\n/YyOt7D1+0cW0lCtyWls/f7SiWdFxLbMRCVjM0Bt8xz34G+fmJvWeye7RQnCjXoNG9cO4r0PZnz/\n/OZ1H8OBbZvw0x03Gfv12A4mmz7fNHD/8DNHfVs4l2FAmIGfqGRsJmKFPcc7g9k2/x52pb+qv46B\nRn3RZ+4/NrFoRSw3Zz1em/0N4nzef77mIuue+n53IEGPFwlTPUQlZDNAHfScpAOmJuNfuW7JY/fv\nOmx8vm2DOWfGcFlbLqeNgZ+ooryN1ESAyam2sVlaUjVDuigsR287eJt2y+UBw/cw0Aiee1AEDPxE\nBZK0ysR5vbe+3h3ggoJ+TSQw7dOo14x3CqbX+QVsN9tZ02nPwdh+6xW+C7Nvv/WKWO+XJwz8RAWR\npJbe7/VR195r1GvYclUTuw+1FgVpb/+boJSLH2fbt+85uuSkE/WKPc05GGWYzGfCwE9UEHEXWXFf\n5Sex5aomHhm+EkMXnxsaDKOmXJyA3c26+TjvXfTJfCYM/EQFETTpyhTUvLXoSezsrLH7yLC5EgZI\ndqXcrUCb9G6pbLjYOlFBmJqQDTTq+HBmznfB8YefOZp6+eGq/jomp9qFSn2UeZF1R5S2zKzjJyoI\n06QrkaX1804KqBs15+9MtQu3OlmSJSnLiIGfqCBMk64mDcE9aU7fRtLVybrVGtoryZKUZcRUD1GG\n0hjMjNqHvhveiLE6mV8zt26tkOX3WU46rAipKhtM9RAVQFoLuyfpVWPSX+/Dtf/uXJg79JxlmpgV\nxq9KybtCVlp3ALbrCVcFq3qIEoh7xT463sIXnzyyZFKTbYsCN28VTRr38KtWrsDOP/gtq1JQ2z4+\nXmH59TjfRZA4FUNsy0xEi8QtEXReZwqY7oAYZdUr5/E0Uj/ONrjr6+/fddj3pGKamBXGpp1yloOv\nZS4BZaqHKKagCVVRX+fmDDjGTQVtXDvo+/j55yy3St042+AeeB3Zexz/ySf1k6QXjk2KKsvB17jH\ntwh4xU8UU9wSwaA/dwdSU+D54pNHcP+uw1g90MDGtYPYf2wCrcnphT46puD+81+dCdwut3fe/xBf\ncHXNbE1O49QvP8A911yEZ1/62UKZ6Ipl8a8dw9bmzXqR+zKXgPKKnyimuCWCpj+viSwacDQFmFnV\nhTuA7xx8ayFd4qSOkub4+wSYas8tebw9p9h96CTe+/DsoimT0218YddhbPjqvlgDscMbmjiwbRPe\n2HET/vyu9bkafC1zCSgDP1FMNqtYRXndn3163aJAl1WAMayJAgCYbs/5tn94Z6qduArHOQkErbbV\nS3GPbxEw8BPFFLdE0PZ1WzevQb0vXqlkFsqS/3aUuQSUOX6iBOI2FbN+XXHiPoBy5L/dytqdk1f8\nRDk1svd4Kl01e6kM+e8q4BU/UcqiTPpxT5ByqnKcdgVZt2EwqfeJ7+LoZcl/VwEDP5FLGksb2k76\n8T7XqcppTU4vKqXMk5oIRu5cZzxZlTEtUkZs0kbUkUbTsCh93/PQXC2OOA3ZqPuiNGnjFT9Rh03T\nsLE3T2P/sQnjHUGUST95Gghd1V+36t0ftz0D5QsHd4k6bJqG7exMmDK1UIgy6Wegv55oe9PSHGjg\noVuuCG2fUK8Jc/glwcBP1GFTkeJNjHpr120m/Tg9cLqxOlYYU68db836Kp+T0mzBKozIjIGfqCNu\nX3v3nULYpB9347Vea9RruOeai4zb5p456zf0Nwdg+56jPd1m6o7QHL+IPAbgZgCnVPXjncdGANwC\n4AyAnwD4fVWd9Hnt9QD+EkANwLdVdUeK204V1o0+6WFNw7y/O7x3Cu5JP852Ok3V3v9wJrAzZ7cI\ngC1XNfHI8JVWz5+c9r8bcR4va5/6qrC54n8cwPWex54H8HFV/QSAfwHwgPdFIlID8E0ANwC4HMDd\nInJ5oq2lSghbhzWtlav8BDUNu+eaiyL1bvHbTlNAjWugUbea3KsA9h+bSOUzu/n9U2+EBn5VfRHA\nac9j+1TVadF3EMAFPi+9GsBrqvq6qp4B8F0AtyXcXio5m6CSRp/0OIt8D118bqTeLWF999MwOd1G\no26XsW1NTlvvr1+O33m8zH3qqyKNHP/nAPzA5/EmgBOu3092HiMysgkqSfuk25xcTM8BgAPbNuHP\n71oPALh/12HjXUmv8vhT7TnU+sT6yt/mCv2hW65Avbb4Hes1wUO3XFHqPvVVkSjwi8iDAGYA7Ey6\nISJyr4iMicjYxEQ6t6RUPGFBZXS8hT7D4t62fWJsTi6m52zfcxQbvroPX9h1eNFJYev3jiwEUuek\n0UuzcxqpD3/YFfrwhiZG7li36O5m5I75ttFl7lNfFbEncInIZzE/6Ps76j/9twXgQtfvF3Qe86Wq\njwJ4FJifuRt3u6jYTOuwOksBmtaq9SuZNA0+2lyxmp5jytG35xT/7amXMLyhie17jmYygBtV2BW6\nqTPl1s1rlsxwLmufnrIOYse64u9U63wJwK2qOmV42o8BXCYil4rIcgCfAbAn3mZSVQTVwZty5t6V\nq8JSOTZXrHGuXqfac7jnf/0o9QHcbol7hV7mPvVuZR7EDg38IvIEgB8BWCMiJ0Xk8wC+AeAcAM+L\nyGER+VbnuatF5DkA6Az+3gdgL4BXATypqiwCpkBBQcV0hTqnuijohKVybCZZxV0E5cBPToc/KQeS\nXqHnbbWsbijzIHZoqkdV7/Z5+K8Nz30bwI2u358D8FzsraNKMqUYgtJAbmGpHHe9fuAtfM4WQRGB\n78SqPpm/6/FrlexWE8GcaqlSFt1U5kFsNmmjwrDNLducIMJWVsrbIigC/6APzK+R+z8+vW7hRPbR\nRh3vn5lZtP2Neq2U6Zhusr3QKCK2bKDCiLJWbdJFsvN2VaeYv2L3IwDG3jybYlq5Yhnu+s0LS5+D\n77YyL7bOK34qFG+axsm3uoOadSrHwCkZ9aseMmnU+/DhzBxCsi2JzKr6to1QADsPvrWohfTuQ62e\nBfuyVr4k/XuUZ1yIhQrFb7GUNNMYfu/vqNcEUCzKpTuf7fT36aamIfUQ9Hzv4i9p6/bxIHtRFmJh\nqocKJa1KC1PLhoef8a/Br4lg5I51GLlzXaSKo7Q4KYYoC6H0Il1V5sqXMmOqhwoljUoL07q4Y2+e\nNvbId0pGTTXcH23Uu1q/776CNi0P6dWLQUjT996anMa1O14oXYqkLBj4qVDiVFp4c9BTZ5a2Rp5u\nz+KJfzxheIezM4e3fu/IQqrHWRT9gadewgftuZh7FK450Fg46ThX2O5FzjeuHcTuQ61F+1TvE0yd\nmcGl257tauA1HQ8BFh4PWnCessFUDxVK1EoLv9mXpqv6oMHcrZvXYPueo7618tPtuUh9cqKQzmd7\nF3BxBno3rh3EI8NXLqp2GmjUAQHemWov7PP9uw7jy6Pp9w/yOx5+dyBM/+QLAz8VStR2AVFaI5vK\nJQcadQxvaGbSikHRaZhmWAh+58G3MDreWjSTduWKZUvmILifmya/42E6CeatRLbKmOqhwgmbfOVm\nG2zqNcFdv3nhkpRJo17D9luviLWdaXAGc037ocDClbSTzjIFXue5aadbvMfj2h0vlHbiU1nwip9K\nzTrYaPBCK1k05uoTLOTpTa2ogbM59FZA0Hf04qq7zBOfyoJX/FRqfm0e/HLQ7TnFyN7jvg3HetFf\nf1V/Hapn2z731/vQntOF8Yig8YeaiHU6qxdX3WWe+FQWDPwFVtQZk73cbr8gZJoEZboa7vYSio16\nDQ/dcoVVusSP7QzjXl51R0nHUe+VKvAXNRDGYapFB/JdMjc63sLW7x9ZGHxsTU5j6/ePAOjddg8Y\nau5NV8PdSI9I57bD+XsKYFHde1DQN22/16r+OvqXL6vEvweKpjSBv6iBMK6gGZO93t8oJ9yHnzm6\npOKkPat4+JmjXdluv78X9ZqgD4C78r7eJ8ar4bBAHIsCP91x08I2eucHmDiDvWGB3+8ugshRmsHd\nqk0dz0uv8CirFI2Ot4w19KbHk/L7e9GeVXinW5mmX42OtzB1ZibWZ//FXeuNLRbcdxem+QFeTqom\n6BizGyfZKE3gz0sg7JW8LHhte8LNYgFywP74z87N33W4Odsc96Q0sve4VYVL0NW7X4WR6Rg3Bxql\nXhGL0lOaVE+ZF03wk5cFr21PuN0eIDUZ6K9bB27v85Ju89uT04sGl1uT0wsVOH7tpP34ddfMy7Gn\n4ipN4K/aP4a8lMzZnnDDcuSr+uupbpfjvQ+iXa3bDrDaGOjsk19zNfcY1MrlNbx/ZukJZuXy2pLH\n3O+X9bGn4ipN4C/rP4aggdM8lMyZ6uSd7ozO9tYCFjap1wQP3ZLu7Fjne4vaO83dWCwp9+4GpcTq\ntT4Afv3/zZnYPBx7Kq7SBH6gfP8YilCp5E1luCdHubc3qNZ85I51kfcn6IQYtJhKUrU+wazlMlvv\nunL3Qe2LTXNy382gNxBVQ6kCf9nkqWQziHPC9Zt05GyvafUop+WwiV+AB8xpE1NDsySaAw28PTmN\ngf463vtgxufa3J873RXUvtjUyz/K+FSV5rBQcqWp6imjolUqBW1vUHWLaTUsU6no9j1LV8lyD5im\n/f04XS/7ly+zKrsEsNAy2bF18xrfK3vF/GSuJL1topTUEgEM/LmWl5JNW0HbO7yhiS1XNRdaH9dE\nsOWqs4OefkHLdMdjKn90An6a34970DnKCcVpg+z0wB/e0DQ2UJucakdqNe1VtTkslBwDf44Vrcvh\n1s1rUO9bfF1b7xNsXDuI9Q/vw3cOvrWQ659Vxe5DrcCr96hX7k7Aj/P91PsEtb6l1+TvTLUX7kKi\nnlC8PfAHGv6VS86J0bmziFqHX7Q7Q8oeA3+ORV10JBc8sXMOwK5/OuF7lR529W4KtKv664EnxOEN\nTTTq4X+1ne91VX8dK1csw+ycLtyRuHfDuQvZuHZwyeeGcXrgj4638L7PDOCgVhG2inZnSNnj4G7O\nFalSaWTv8SV9eGbn1How1M0ZoPSbm+GUfgZV9cxY5OIPbNu0pALIWdLQb+nA/ccm8LXbr1z0ue9/\nOBPaN6c1Oe373QDAr31kmfH42g7YVm0OCyXHwE+x+AWlOKmFVf11vPfhzKKgWK/JoiAXNI/BjynI\neplaHwctHeg9EduWjprmBUwaZhVHKeUt6xwW6h4GforMFJSitEcA5q9Kb/rEx7Drn04s/gNX5I1z\nx2N7Aoo6ScsvdTK8oYmxN09j58G3Ale/Mk1gWz3Q8D2JRi3lLdKdIWWPOX6KzBSUVJeWJdZrsmTA\nF5i/0v/a7Vdi/7GJJSWSzmpYXqayT69u5LaDUif7j02ELnk4q+o7LrFx7aBvVVPUxWKIomDgJ+uA\n6jAFn3enl5YljtyxDiN3rlv02F/ctR7jX7kOwxua1hUpUWrV/aqh4qiJWA2q2wRj5z28A/X7j034\nnkRrhjV2OWBLaWCqp+LitIUIasxmSjnEeS+3qKmPFcv6Es/enVNdtFiKu4GbO4ce1tDNPWbh3db7\ndx32fY1zh5BkwJazeckk9IpfRB4TkVMi8orrsTtF5KiIzInIUMBr3xCRl0XksIiMpbXRlJ44k3/c\nM1JtHg9iO1ch6p1BWKWNX82+l3PyCbvbCLrDWNVfD+xFFNRbP0kpL2fzUhCbK/7HAXwDwN+6HnsF\nwO0A/sri9RtV9RfRN416Ic7kn/3HJiI9HsS2IiXJnYGfc1Ysw8oVyxb14HGPNbhPPmF3G0mqaoJK\nMZMM2Jq2+YtP9nZ9Y8qn0MCvqi+KyCWex14FADHkIak44ixgk/ZMUZsAZ1urbrsNk9NtrFwx/9e/\nf/ky3PSJj2H/sQnfwB3UWXN0vLWw/XGCabdKMU3bPKuauw6v1HvdzvErgB+KyCyAv1LVR01PFJF7\nAdwLABdddFGXN4sccSb/ZLHaWdI7Ay9nzQB0/r/7UMuYSgl6zzSCaDdKMYO2OY8dXqm3ul3V89uq\nuh7ADQD+SEQ+aXqiqj6qqkOqOjQ4GD1XDESvTqF4bSGy6iFk08/GpqLHNDPXNK4R9J55bYYW9j2w\nLLTaunrFr6qtzv9PicjTAK4G8GI3PqsIi5bkVdQrzjzPFPXbto1rBxelcaLWyDvv+QVDBU4eg6iz\nzV988ohx4hhVV9cCv4isBNCnqr/q/HwdgK926/OKsmhJWZhOFnkoIQw7kZlaNQQFQ2eBl16nuJLw\nW+sXYB8fsgj8IvIEgE8BOE9ETgJ4CMBpAP8TwCCAZ0XksKpuFpHVAL6tqjcCOB/A050B4GUA/k5V\n/6E7u8HWtHnQy7su08pc3WxqVsRmaHm+O6PsiAashZqVoaEhHRuLVvZvuoprDjRwYNumtDat5/Jw\nBW2rV8fArzFavSaAYklJpmm8wv29DvTXoTo/8zjsOy7S8aBqEZFDqmqcV+VWmpm7tldjRfqHW7Rx\ni17ddfml9fy6cdo0NYv6HbMZGpVBaQK/zS1t0QJp0cYt4pZ5ek/G3sFY73GMciIJe27RvmOiNJQm\n8APhV2NF+0detHGLODlwv5Pxdw6+tfDnfidn21p957lBivYdE6WhVN05w+r4i/aPvGhL6pkWVI96\nMvby1sr71aj7tX+2GXgt2ndMlIbSBH6bplRF+0eex8XWg06uo+Mt7D7UWrKgetBEOtuTrvt5fpPO\n/No/2zQ1y+N3TNRtpUn12KRxilaOl7dSvLAxkjipNNu0jffkHLX9s0nevmOiXihN4LdJ4xTxH3me\nqkjCAnucVJrfydgr7snZtoIr7DsuUiUYkY3SBH7bipI8BdKiCQvscap6bFosRAm0TpBuTU4v6skT\nt4KraJVgRDZKE/iLlsYporDAHvcYBJ2MnUB+/67DVpOr3J9vasQWJWAnqQTjnQLlVWkGd+N0maRo\nwgZC0z4GUVeRsqkQilrBFbcSjCtgUZ6V5oofYBqn22zGSNI8BlGvtm2CetQKrriT0oo2Z4SqpVSB\nn7qvlyfXqFfbYRVCcVJ/cdNXRZszQtVSmlQPlU/UeRd+qShnSlfctFPc9FXR5oxQtfCKn3Ir6tX2\n8IYmxt49xv/iAAAGAUlEQVQ8jSf+8QRmVVETwd3/8UI8Mnxlou2Ic5fDYgPKM17xU25FvdqOM3O4\nW1hsQHlWmn78RGVdk4HIRiX78VO1+NXIc0CVyA4DPxWOaTbtQH8d70y1lzyfA6pEizHHT4VjqpFX\nBTttEllg4KfCMaVu3p1uc0CVyAJTPVQ4QbNpOXubKByv+Ck3wlZQc3DxFKJkeMVPuRCl/XER11Ug\nyhMG/gIrU9vfqE3NmNIhio+Bv6DKtkAIa/CJeoc5/oIKukIuIjY1I+odBv6CKtsVMgdsiXqHgb+g\nynaFzKZmRL3DHH9BlbHtLwdsiXqDgb+gWNJIRHEx8BcYr5CJKI7QHL+IPCYip0TkFddjd4rIURGZ\nExFj/2cRuV5EjovIayKyLa2NJiKi+GwGdx8HcL3nsVcA3A7gRdOLRKQG4JsAbgBwOYC7ReTyeJtp\nz3baPxFRVYWmelT1RRG5xPPYqwAgIn4vcVwN4DVVfb3z3O8CuA3AP8fc1lBlm9RERNQN3SznbAI4\n4fr9ZOexrinbpCYiom7ITR2/iNwrImMiMjYxMRHrPco2qYmIqBu6GfhbAC50/X5B5zFfqvqoqg6p\n6tDg4GCsDyzbpCYiom7oZuD/MYDLRORSEVkO4DMA9nTx8zjtn4jIgk055xMAfgRgjYicFJHPi8jv\nishJAL8F4FkR2dt57moReQ4AVHUGwH0A9gJ4FcCTqnq0WzsCcNo/EZENUdWst2GJoaEhHRsby3oz\nyFKZ1gUgKioROaSqxnlVbpy5S4mwhJaoeHJT1UPFxBJaouJh4KdEWEJLVDwM/JQIS2iJioeBnxJh\nCS1R8XBwlxLhugBExcPAT4lxXQCiYmGqh4ioYhj4iYgqhoGfiKhiGPiJiCqGgZ+IqGIY+ImIKiaX\n3TlFZALAmym+5XkAfpHi++VZVfa1KvsJVGdfuZ/JXKyqVqtY5TLwp01ExmzblRZdVfa1KvsJVGdf\nuZ+9w1QPEVHFMPATEVVMVQL/o1lvQA9VZV+rsp9AdfaV+9kjlcjxExHRWVW54icioo5CB34ReUxE\nTonIK67HzhWR50XkXzv/X2V47Rsi8rKIHBaR3K/sbtjXO0XkqIjMiYixSkBErheR4yLymohs680W\nx5NwP8twTEdE5JiIvCQiT4vIgOG1RT+mtvtZmGNq2M8/6ezjYRHZJyKrDa/t7fFU1cL+B+CTAP4D\ngFdcj/13ANs6P28D8HXDa98AcF7W+5BwX/89gDUA/i+AIcPragB+AuA3ACwHcATA5VnvT9r7WaJj\neh2AZZ2fv+7397ckxzR0P4t2TA37+W9cP/8XAN/Kw/Es9BW/qr4I4LTn4dsA/E3n578BMNzTjeoS\nv31V1VdVNWxV86sBvKaqr6vqGQDfxfx3lEsJ9rNwDPu6T1VnOr8eBHCBz0vLcExt9rNQDPv5S9ev\nKwH4Dar2/HgWOvAbnK+qP+v8/P8AnG94ngL4oYgcEpF7e7NpmWgCOOH6/WTnsTIq2zH9HIAf+Dxe\ntmNq2k+gBMdURP5URE4AuAfAV3ye0vPjWcbAv0Dn76NMZUu/rarrAdwA4I9E5JO92zLqktIcUxF5\nEMAMgJ1Zb0s3Wexn4Y+pqj6oqhdifh/vy3p7gHIG/p+LyMcAoPP/U35PUtVW5/+nADyN+dutMmoB\nuND1+wWdx0qnLMdURD4L4GYA93QuXrxKcUwt9rM0x7RjJ4AtPo/3/HiWMfDvAfB7nZ9/D8D/9j5B\nRFaKyDnOz5gfaHrF+7yS+DGAy0TkUhFZDuAzmP+OSqUsx1RErgfwJQC3quqU4WmFP6Y2+1mGYyoi\nl7l+vQ3AMZ+n9f54Zj0SnnAU/QkAPwPQxnxe7PMA/i2A/wPgXwH8EMC5neeuBvBc5+ffwPzI+REA\nRwE8mPW+xNzX3+38/CGAnwPY693Xzu83AvgXzFcO5Hpf4+5niY7pa5jP9x7u/Petkh7T0P0s2jE1\n7OduzJ+sXgLwDIBmHo4nZ+4SEVVMGVM9REQUgIGfiKhiGPiJiCqGgZ+IqGIY+ImIKoaBn4ioYhj4\niYgqhoGfiKhi/j8VUTACOa/ldQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f744ab70748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamoslo en un scatter plot\n",
    "plt.scatter(val_predicted_home_prices2, val_y );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar el primer modelo se comporta demasiado bien, pero es que está sobreajustado, y luego con el test se comportará mal. Es mejor el segundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora del modelo\n",
    "\n",
    "Vamos a cambiar el número de ramas que puede tener el modelo (no siempre más es mejor), pues tiene que servir para luego predecir bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  0\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  0\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  0\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  0\n"
     ]
    }
   ],
   "source": [
    "#  Ahora vamos a ajustar mejor el modelo definiendo cuantas ramas tendrá el arbol\n",
    "\n",
    "def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(predictors_train, targ_train)\n",
    "    preds_val = model.predict(predictors_val)\n",
    "    mae = mean_absolute_error(targ_val, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
