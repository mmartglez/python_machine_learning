{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to regression\n",
    "\n",
    "Realicemos una predicción basada en una regresión lineal. \n",
    "Se parte de los datos analizados, normalizados y acotados logrados en el punto 0, para el training.\n",
    "\n",
    "Este método se basa en hacer una predicción basada en regresiones lineales con y sin regularización.\n",
    "\n",
    "Partiendo de una contrucción del modelo, haremos un proceso iterativo de validación y ajuste del mismo (modificando parámetros y variables), hasta obtener el que mejor predice nuestra target, sin infra o sobreajustes\n",
    "\n",
    "## Importación de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.805765</td>\n",
       "      <td>729.805765</td>\n",
       "      <td>56.877145</td>\n",
       "      <td>10460.434454</td>\n",
       "      <td>6.094715</td>\n",
       "      <td>5.576527</td>\n",
       "      <td>1971.194235</td>\n",
       "      <td>1984.818806</td>\n",
       "      <td>439.128346</td>\n",
       "      <td>46.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.069321</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.402158</td>\n",
       "      <td>421.402158</td>\n",
       "      <td>42.339638</td>\n",
       "      <td>9862.564977</td>\n",
       "      <td>1.376542</td>\n",
       "      <td>1.113638</td>\n",
       "      <td>30.190353</td>\n",
       "      <td>20.640669</td>\n",
       "      <td>432.964939</td>\n",
       "      <td>161.471529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.090410</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.383022</td>\n",
       "      <td>0.278112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>364.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9473.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2188.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           Id   MSSubClass        LotArea  OverallQual  \\\n",
       "count  1457.000000  1457.000000  1457.000000    1457.000000  1457.000000   \n",
       "mean    728.805765   729.805765    56.877145   10460.434454     6.094715   \n",
       "std     421.402158   421.402158    42.339638    9862.564977     1.376542   \n",
       "min       0.000000     1.000000    20.000000    1300.000000     1.000000   \n",
       "25%     364.000000   365.000000    20.000000    7540.000000     5.000000   \n",
       "50%     729.000000   730.000000    50.000000    9473.000000     6.000000   \n",
       "75%    1093.000000  1094.000000    70.000000   11600.000000     7.000000   \n",
       "max    1459.000000  1460.000000   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1457.000000  1457.000000   1457.000000  1457.000000  1457.000000   \n",
       "mean      5.576527  1971.194235   1984.818806   439.128346    46.645161   \n",
       "std       1.113638    30.190353     20.640669   432.964939   161.471529   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1972.000000   1994.000000   383.000000     0.000000   \n",
       "75%       6.000000  2000.000000   2004.000000   712.000000     0.000000   \n",
       "max       9.000000  2010.000000   2010.000000  2188.000000  1474.000000   \n",
       "\n",
       "               ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "count          ...               1457.000000   1457.000000   1457.000000   \n",
       "mean           ...                  0.003432      0.082361      0.002059   \n",
       "std            ...                  0.058500      0.275008      0.045345   \n",
       "min            ...                  0.000000      0.000000      0.000000   \n",
       "25%            ...                  0.000000      0.000000      0.000000   \n",
       "50%            ...                  0.000000      0.000000      0.000000   \n",
       "75%            ...                  0.000000      0.000000      0.000000   \n",
       "max            ...                  1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "count  1457.000000            1457.000000            1457.000000   \n",
       "mean      0.868909               0.069321               0.002745   \n",
       "std       0.337616               0.254086               0.052342   \n",
       "min       0.000000               0.000000               0.000000   \n",
       "25%       1.000000               0.000000               0.000000   \n",
       "50%       1.000000               0.000000               0.000000   \n",
       "75%       1.000000               0.000000               0.000000   \n",
       "max       1.000000               1.000000               1.000000   \n",
       "\n",
       "       SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "count           1457.000000           1457.000000           1457.000000   \n",
       "mean               0.008236              0.013727              0.821551   \n",
       "std                0.090410              0.116395              0.383022   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              1.000000   \n",
       "50%                0.000000              0.000000              1.000000   \n",
       "75%                0.000000              0.000000              1.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Partial  \n",
       "count            1457.000000  \n",
       "mean                0.084420  \n",
       "std                 0.278112  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 222 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerías a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importación de datos\n",
    "data = pd.read_csv(\"data/PreciosCasas/train_final.csv\", sep='\\t', encoding='utf-8') \n",
    "\n",
    "# print a summary of the data in Melbourne data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1457, 222)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reescalado\n",
    "\n",
    "Al contrario que en otros modelos, cuando se aplican modelos de regresión lineal con terminos de penalización (como Lasso o Ridge), debemos tener las variables en la misma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data = (data - data.min()) / data.max()\n",
    "print(data.max().max())\n",
    "print(data.min().min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id  MSSubClass   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0  0.000000    0.210526  0.033218          0.6     0.444444   0.065174   \n",
      "1  0.000685    0.000000  0.038561          0.5     0.777778   0.051741   \n",
      "2  0.001370    0.210526  0.046226          0.6     0.444444   0.064179   \n",
      "3  0.002055    0.263158  0.038328          0.6     0.444444   0.021393   \n",
      "4  0.002740    0.210526  0.060210          0.7     0.444444   0.063682   \n",
      "\n",
      "   YearRemodAdd  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF          ...            \\\n",
      "0      0.026368    0.322669         0.0   0.064212          ...             \n",
      "1      0.012935    0.446984         0.0   0.121575          ...             \n",
      "2      0.025871    0.222121         0.0   0.185788          ...             \n",
      "3      0.009950    0.098720         0.0   0.231164          ...             \n",
      "4      0.024876    0.299360         0.0   0.209760          ...             \n",
      "\n",
      "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
      "0             0.0           0.0           0.0          1.0   \n",
      "1             0.0           0.0           0.0          1.0   \n",
      "2             0.0           0.0           0.0          1.0   \n",
      "3             0.0           0.0           0.0          1.0   \n",
      "4             0.0           0.0           0.0          1.0   \n",
      "\n",
      "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
      "0                    0.0                    0.0                   0.0   \n",
      "1                    0.0                    0.0                   0.0   \n",
      "2                    0.0                    0.0                   0.0   \n",
      "3                    1.0                    0.0                   0.0   \n",
      "4                    0.0                    0.0                   0.0   \n",
      "\n",
      "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                   0.0                   1.0                    0.0  \n",
      "1                   0.0                   1.0                    0.0  \n",
      "2                   0.0                   1.0                    0.0  \n",
      "3                   0.0                   0.0                    0.0  \n",
      "4                   0.0                   1.0                    0.0  \n",
      "\n",
      "[5 rows x 220 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos: todas como columnas y el SalesPrice como target\n",
    "\n",
    "X= data.ix[:, data.columns != 'Unnamed: 0']\n",
    "X= X.ix[:, X.columns != 'SalePrice']\n",
    "\n",
    "print (X.head())\n",
    "\n",
    "y= data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del modelo de Regresión\n",
    "\n",
    "Haremos primero una regresión lineal sin regularizar, analizaremos el modelo, y luego iremos probando con los distintos tipos de regularización a ver como lo vamos mejorando.\n",
    "\n",
    "- **A. Regresión lineal sin regularizar**\n",
    "\n",
    "    Para ser capaces de ir validando el modelo, lo separaremos en dos grupos, predictors and target. Lo haremos mediando un split con un número generaro aleatorio. Como queremos que todas las veces que ejecutemos el modelo nos salga lo mismo, estableceremos el argumento de random_state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "#Separamos los datos en dos grupos, \n",
    "train_X, val_X, train_y, val_y = train_test_split( X, y,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de Regresión lineal \n",
    "LR = LinearRegression()\n",
    "LR.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional_Sev........... -6.0368e+09\n",
      "Functional_Typ........... -6.0368e+09\n",
      "PavedDrive_N............. -6.0368e+09\n",
      "Exterior2nd_Wd Shng......  5.3896e+09\n",
      "Exterior2nd_Wd Sdng......  5.3896e+09\n"
     ]
    }
   ],
   "source": [
    "#Variables que más influyen\n",
    "maxcoef = np.argsort(-np.abs(LR.coef_))\n",
    "coef = LR.coef_[maxcoef]\n",
    "for i in range(0, 5):\n",
    "    print(\"{:.<025} {:< 010.4e}\".format(data.columns[maxcoef[i]], coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo está demasiado sobreajustado y que el error es increible ( se ve en el grafico que como modelo, no mola nada). Seguramente es por culpa de esas variables, la de funcionalidad porque sí, será relevante para el precio que esté bien la casa, pero los años lo definen mejor y estará relacionado, y el tema de cuanto ocupa el exterior, lo mismo, debemos tener otra variables dependiente \n",
    "\n",
    "*Nota: se supone que esto se miró en el punto de \"Analisis de los datos\" y con los mapas de calor se quitaron las variables dependientes, así que avancemos en ajustar este modelo y veamos que va pasando*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29656030.3402\n"
     ]
    }
   ],
   "source": [
    "prediccion = LR.predict(val_X)\n",
    "print(mean_absolute_error(val_y, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEJCAYAAACT/UyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53e09b4978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamoslo en un scatter plot\n",
    "plt.scatter(prediccion,val_y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **B. Regresión lineal con Lasso**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de Regresión lineal Lasso\n",
    "Ls = LassoCV()\n",
    "Ls.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalBsmtSF..............  6.0526e-02\n",
      "LotArea..................  4.5395e-02\n",
      "1stFlrSF.................  3.1922e-02\n",
      "YrSold................... -2.4295e-02\n",
      "OverallQual..............  2.3235e-02\n"
     ]
    }
   ],
   "source": [
    "#Variables que más influyen\n",
    "maxcoef = np.argsort(-np.abs(Ls.coef_))\n",
    "coef = Ls.coef_[maxcoef]\n",
    "for i in range(0, 5):\n",
    "    print(\"{:.<025} {:< 010.4e}\".format(data.columns[maxcoef[i]], coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora mejor, es cierto que el tamaño total de la parcela (TotalBsmtSF) y la calidad (OverallQual) son variables a tener en cuenta para decidir el precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **C. Regresión lineal Ridge**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=(0.1, 1.0, 10.0), cv=None, fit_intercept=True, gcv_mode=None,\n",
       "    normalize=False, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de Regresión lineal Ridge\n",
    "Rr = RidgeCV()\n",
    "Rr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalBsmtSF..............  3.9882e-02\n",
      "LotArea..................  3.5368e-02\n",
      "1stFlrSF.................  2.4147e-02\n",
      "OverallQual..............  2.2770e-02\n",
      "YrSold................... -2.1352e-02\n"
     ]
    }
   ],
   "source": [
    "#Variables que más influyen\n",
    "maxcoef = np.argsort(-np.abs(Rr.coef_))\n",
    "coef = Rr.coef_[maxcoef]\n",
    "for i in range(0, 5):\n",
    "    print(\"{:.<025} {:< 010.4e}\".format(data.columns[maxcoef[i]], coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar a lo obtenido en L1, así que bien. Veamos que pasa si juntamos ahora las dos regularizaciones\n",
    "\n",
    "\n",
    "- **D. Regresión lineal elástica**\n",
    "\n",
    "La ventaja de juntar las dos, es que si dos variables están correlacionadas, va a mantener las dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modelo de Regresión lineal elastic net\n",
    "EN = ElasticNetCV(l1_ratio=np.linspace(0.1, 1.0, 5)) \n",
    "# intentamos aplanar el Rr \n",
    "train_EN = EN.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalBsmtSF..............  6.0526e-02\n",
      "LotArea..................  4.5395e-02\n",
      "1stFlrSF.................  3.1922e-02\n",
      "YrSold................... -2.4295e-02\n",
      "OverallQual..............  2.3235e-02\n"
     ]
    }
   ],
   "source": [
    "#Variables que más influyen\n",
    "maxcoef = np.argsort(-np.abs(EN.coef_))\n",
    "coef = EN.coef_[maxcoef]\n",
    "for i in range(0, 5):\n",
    "    print(\"{:.<025} {:< 010.4e}\".format(data.columns[maxcoef[i]], coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, similar a los otros dos, pero claro... ¿cuál es mejor?\n",
    "\n",
    "## Selección\n",
    "\n",
    "Comparemos todas las opciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90757635  0.9039292   0.90771521]\n"
     ]
    }
   ],
   "source": [
    "model = [Ls, Rr, EN]\n",
    "M = len(model)\n",
    "CV = 5\n",
    "score = np.empty((M, CV))\n",
    "for i in range(0, M):\n",
    "    score[i, :] = cross_val_score(model[i], train_X, train_y, cv=CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90757635  0.9039292   0.90771521]\n"
     ]
    }
   ],
   "source": [
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-bfe76d6a9a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testID' is not defined"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame({'Id': testID, 'SalePrice': np.exp(EN.predict(test_X))})\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-08aa45b55f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediccion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediccion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Veamoslo en un scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediccion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "prediccion = M.predict(val_X)\n",
    "print(mean_absolute_error(val_y, prediccion))\n",
    "\n",
    "# Veamoslo en un scatter plot\n",
    "plt.scatter(prediccion,val_y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal no parece funcionar muy bien, necesita regularización (cualquiera de las tres ya es buena), no obstante, para estos datos, no parece que este modelo sea el mejor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
