{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
      "\n",
      "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
      "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
      "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
      "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
      "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
      "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
      "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
      "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
      "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
      "\n",
      "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
      "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
      "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
      "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
      "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
      "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
      "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
      "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
      "\n",
      "           SalePrice  \n",
      "count    1460.000000  \n",
      "mean   180921.195890  \n",
      "std     79442.502883  \n",
      "min     34900.000000  \n",
      "25%    129975.000000  \n",
      "50%    163000.000000  \n",
      "75%    214000.000000  \n",
      "max    755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# save filepath to variable for easier access\n",
    "# melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(\"data/train.csv\") \n",
    "# print a summary of the data in Melbourne data\n",
    "print(melbourne_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver que variables elegimos\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.828082</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>6.517808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.264932</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>1.625393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.500000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.500000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean    10516.828082  1971.267808  1162.626712   346.992466     1.565068   \n",
       "std      9981.264932    30.202904   386.587738   436.528436     0.550916   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7553.500000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9478.500000  1973.000000  1087.000000     0.000000     2.000000   \n",
       "75%     11601.500000  2000.000000  1391.250000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  4692.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1460.000000   1460.000000  \n",
       "mean       2.866438      6.517808  \n",
       "std        0.815778      1.625393  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Queremos prededir el precio, será nuestro target, y cogeremos unas variables como pedictores \n",
    "y= melbourne_data.SalePrice\n",
    "print(y.head())\n",
    "melbourne_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = melbourne_data[melbourne_predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree models\n",
    "El modelo que vamos a hacer es  scikit-learn, y luego validamos que tal es mediante Mean Absolute Error (also called MAE). Let's break down this metric starting with the last word, error.\n",
    "\n",
    "The prediction error for each house is: \n",
    "error=actual−predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_training= test. Making predictions for the following 5 houses:\n",
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "0     8450       2003       856       854         2             3   \n",
      "1     9600       1976      1262         0         2             3   \n",
      "2    11250       2001       920       866         2             3   \n",
      "3     9550       1915       961       756         1             3   \n",
      "4    14260       2000      1145      1053         2             4   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "0             8  \n",
      "1             6  \n",
      "2             6  \n",
      "3             7  \n",
      "4             9  \n",
      "The predictions are\n",
      "[ 208500.  181500.  223500.  140000.  250000.]\n",
      "And the real is\n",
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n",
      "error para el conjunto de training es: \n",
      "62.3543378995\n",
      "2_ Training<> Test. Making predictions for the following 5 houses:\n",
      "     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "529    32668       1957      2515         0         3             4   \n",
      "491     9490       1941       958       620         1             3   \n",
      "459     7015       1950       979       224         1             3   \n",
      "279    10005       1977      1156       866         2             4   \n",
      "655     1680       1971       525       567         1             3   \n",
      "\n",
      "     TotRmsAbvGrd  \n",
      "529             9  \n",
      "491             5  \n",
      "459             5  \n",
      "279             8  \n",
      "655             6  \n",
      "The predictions are\n",
      "[ 335000.  205000.  134800.  207500.   89500.]\n",
      "And the real is\n",
      "529    200624\n",
      "491    133000\n",
      "459    110000\n",
      "279    192000\n",
      "655     88000\n",
      "Name: SalePrice, dtype: int64\n",
      "error para el conjunto de training es: \n",
      "error es: \n",
      "32539.9890411\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Separamos los datos en dos grupos\n",
    "# split data into training and validation data, for both predictors and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n",
    "\n",
    "#1_ Si no cogieramos el training y validación: Hacemos el modelo\n",
    "melbourne_model= DecisionTreeRegressor()\n",
    "melbourne_model.fit(X,y)\n",
    "\n",
    "#Veamos como funciona\n",
    "print(\"1_training= test. Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))\n",
    "print(\"And the real is\")\n",
    "print(y.head())\n",
    "\n",
    "val_predicted_home_prices = melbourne_model.predict(X)\n",
    "print(\"error para el conjunto de training es: \")\n",
    "print (mean_absolute_error(y,val_predicted_home_prices ))\n",
    "\n",
    "#2_ Si cogemos el training y validación: Hacemos el modelo\n",
    "melbourne_model= DecisionTreeRegressor()\n",
    "melbourne_model.fit(train_X,train_y)\n",
    "\n",
    "#Veamos como funciona\n",
    "print(\"2_ Training<> Test. Making predictions for the following 5 houses:\")\n",
    "print(val_X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(val_X.head()))\n",
    "print(\"And the real is\")\n",
    "print(val_y.head())\n",
    "\n",
    "#Error cometido en esta medicion MAE\n",
    "print(\"error para el conjunto de training es: \") \n",
    "val_predicted_home_prices = melbourne_model.predict(val_X)\n",
    "print(\"error es: \")\n",
    "print (mean_absolute_error(val_y,val_predicted_home_prices ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  35190\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  27825\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  32662\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  33382\n"
     ]
    }
   ],
   "source": [
    "# 3_ Ahora vamos a ajustar mejor el modelo definiendo cuantas ramas tendrá el arbol\n",
    "\n",
    "def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(predictors_train, targ_train)\n",
    "    preds_val = model.predict(predictors_val)\n",
    "    mae = mean_absolute_error(targ_val, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model\n",
    "The random forest uses many trees, and it makes a prediction by average the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23781.467032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionar variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "Mean Absolute Error from dropping columns with Missing Values:\n",
      "18055.5090564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#1) Limpiar datos, borrando valores perdidos\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "melb_data= melbourne_data\n",
    "melb_target = melbourne_data.SalePrice\n",
    "melb_predictors = melbourne_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# For the sake of keeping the example simple, we'll use only numeric predictors. \n",
    "melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "\n",
    "#funcion para calcular MAE\n",
    "X_train, X_test, y_train, y_test = train_test_split(melb_numeric_predictors, \n",
    "                                                    melb_target,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor(n_estimators=60, max_depth=10, min_samples_split=10, random_state=29011982)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "cols_with_missing = [col for col in X_train.columns \n",
    "                                 if X_train[col].isnull().any()]\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test  = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print (cols_with_missing)\n",
    "print(\"Mean Absolute Error from dropping columns with Missing Values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
       "       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
       "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "17785.7748086\n"
     ]
    }
   ],
   "source": [
    "#2) Imputation\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "#print(pd.DataFrame(imputed_X_train).sample (5))\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(imputed_X_train)  # como son tipos distintos no aplican las mismas propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while Track What Was Imputed:\n",
      "17804.8957325\n"
     ]
    }
   ],
   "source": [
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns \n",
    "                                 if X_train[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ¿el modelo es estable? hago el cross-validation para un random forest y para un boosting\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20037.52170088  21254.58768328  18538.27235294]\n",
      "[ 0.80786494  0.85106733  0.84485583]\n"
     ]
    }
   ],
   "source": [
    "score_dataset_cv(reduced_X_train, reduced_X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17838.61492361  18723.1462148   15069.57012214]\n",
      "[ 0.79428757  0.8755134   0.89312167]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor()\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(reduced_X_train, reduced_X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.6, 0.7, 0.8], 'min_weight_fraction_leaf': [0.2, 0.1, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiperparámetros: mirar que parámetros son los que debo cambiar para mi modelo\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators': [70, 100, 120], 'max_depth': [3, 5, 7, 10], 'subsample': [0.60, 0.7, 0.80],'min_weight_fraction_leaf':[0.20, 0.1, 0.05]}\n",
    "gbr = GradientBoostingRegressor()\n",
    "clf = GridSearchCV(gbr, parameters)\n",
    "clf.fit(reduced_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.11714339,  0.11063226,  0.12684703,  0.1728754 ,  0.17218852,\n",
       "         0.16924175,  0.17997193,  0.18668445,  0.18607386,  0.12267931,\n",
       "         0.13055062,  0.13252672,  0.17671243,  0.17018708,  0.16864181,\n",
       "         0.21145304,  0.20427322,  0.21248802,  0.15325721,  0.15230163,\n",
       "         0.12965608,  0.19285822,  0.18939575,  0.17586199,  0.22160554,\n",
       "         0.21080907,  0.20912997,  0.10416691,  0.12761633,  0.12933501,\n",
       "         0.1494631 ,  0.14823429,  0.15870674,  0.1798652 ,  0.18544054,\n",
       "         0.18467911,  0.1501797 ,  0.1607914 ,  0.17250355,  0.21540658,\n",
       "         0.24059312,  0.2426095 ,  0.27144027,  0.26941133,  0.28824711,\n",
       "         0.18110792,  0.18133903,  0.18775423,  0.24791773,  0.26486731,\n",
       "         0.28458309,  0.29874619,  0.3225166 ,  0.33392493,  0.11015924,\n",
       "         0.10737125,  0.11646843,  0.15099899,  0.15411075,  0.16042129,\n",
       "         0.17211509,  0.17684865,  0.19291862,  0.16465108,  0.16844392,\n",
       "         0.17785048,  0.22965948,  0.26353717,  0.27792478,  0.28878069,\n",
       "         0.29476722,  0.30583556,  0.21441507,  0.22577397,  0.23381424,\n",
       "         0.34391602,  0.33021855,  0.35114225,  0.36516158,  0.38948075,\n",
       "         0.3805186 ,  0.10505954,  0.13249048,  0.10659838,  0.15436101,\n",
       "         0.15138062,  0.15655613,  0.18316062,  0.19992097,  0.18030087,\n",
       "         0.1683201 ,  0.17862733,  0.16732383,  0.2354598 ,  0.24290546,\n",
       "         0.26095899,  0.26981537,  0.29492331,  0.31533702,  0.24293486,\n",
       "         0.25075618,  0.25162387,  0.35722462,  0.35562849,  0.37873658,\n",
       "         0.40811761,  0.4387536 ,  0.44904947]),\n",
       " 'mean_score_time': array([ 0.00134548,  0.00145904,  0.00148217,  0.00166368,  0.00177089,\n",
       "         0.00241216,  0.00215459,  0.00169206,  0.00206288,  0.00165788,\n",
       "         0.00165192,  0.00163658,  0.00176136,  0.00162903,  0.00171423,\n",
       "         0.00292404,  0.0021979 ,  0.00200089,  0.00145419,  0.00166758,\n",
       "         0.00174999,  0.00196195,  0.00153899,  0.00331982,  0.0023307 ,\n",
       "         0.00195638,  0.00186769,  0.00152906,  0.00170414,  0.00157682,\n",
       "         0.00186666,  0.00151634,  0.0017813 ,  0.00215952,  0.00206033,\n",
       "         0.00252867,  0.001851  ,  0.00178361,  0.00388662,  0.00208926,\n",
       "         0.00191037,  0.00355713,  0.00223192,  0.0028158 ,  0.00211692,\n",
       "         0.00206168,  0.00188835,  0.00235446,  0.00225989,  0.00336266,\n",
       "         0.00181492,  0.00271511,  0.00279895,  0.00243497,  0.00141279,\n",
       "         0.00146063,  0.00144807,  0.001779  ,  0.00172758,  0.00221133,\n",
       "         0.00205016,  0.00199564,  0.0018096 ,  0.00186292,  0.00194144,\n",
       "         0.00157348,  0.00216444,  0.00375223,  0.00261815,  0.00369732,\n",
       "         0.00260035,  0.00254011,  0.00239333,  0.00215721,  0.00199421,\n",
       "         0.00251683,  0.00280118,  0.0025657 ,  0.0031182 ,  0.00241335,\n",
       "         0.00277217,  0.00162776,  0.00179116,  0.00171216,  0.00189789,\n",
       "         0.00172289,  0.00348552,  0.00188486,  0.00203657,  0.00179164,\n",
       "         0.00152787,  0.00201734,  0.00169945,  0.00207567,  0.00253987,\n",
       "         0.002225  ,  0.00271265,  0.00212153,  0.00307616,  0.0023694 ,\n",
       "         0.00228039,  0.00212709,  0.00307631,  0.00270001,  0.00262984,\n",
       "         0.00511591,  0.00293008,  0.00302529]),\n",
       " 'mean_test_score': array([ 0.78350144,  0.78457752,  0.77991719,  0.79563271,  0.79477609,\n",
       "         0.79431563,  0.80365568,  0.79909173,  0.80158269,  0.83536301,\n",
       "         0.83572328,  0.8308875 ,  0.83989148,  0.83740334,  0.8415559 ,\n",
       "         0.84340321,  0.84539483,  0.84368825,  0.85172258,  0.8530946 ,\n",
       "         0.85168265,  0.85052992,  0.85091074,  0.84719844,  0.8532906 ,\n",
       "         0.84944614,  0.84816658,  0.78631237,  0.77919019,  0.78022763,\n",
       "         0.79729935,  0.79233056,  0.79513444,  0.8016102 ,  0.80382043,\n",
       "         0.80285868,  0.83868128,  0.8343607 ,  0.83285429,  0.83796568,\n",
       "         0.84124133,  0.8386922 ,  0.84190888,  0.83749431,  0.84078784,\n",
       "         0.8527653 ,  0.85271024,  0.84900645,  0.84986879,  0.84739886,\n",
       "         0.84875916,  0.84828401,  0.85282111,  0.84622147,  0.78948047,\n",
       "         0.78002928,  0.778824  ,  0.79877648,  0.79322155,  0.79856886,\n",
       "         0.79841858,  0.79754873,  0.80301895,  0.83304271,  0.83486067,\n",
       "         0.83082684,  0.84278881,  0.83957634,  0.83675852,  0.8382215 ,\n",
       "         0.83813744,  0.84180764,  0.84704118,  0.84794089,  0.85092953,\n",
       "         0.85127002,  0.8486924 ,  0.84981132,  0.84626913,  0.8531923 ,\n",
       "         0.84261747,  0.785761  ,  0.77970546,  0.77836121,  0.79506055,\n",
       "         0.79401551,  0.79079335,  0.80536035,  0.79832825,  0.80128029,\n",
       "         0.83701425,  0.83667493,  0.83118502,  0.84258555,  0.84082727,\n",
       "         0.83750907,  0.84632181,  0.83943606,  0.84157607,  0.84949842,\n",
       "         0.85007268,  0.84822857,  0.84695395,  0.85201167,  0.85191881,\n",
       "         0.84788386,  0.84559   ,  0.84798434]),\n",
       " 'mean_train_score': array([ 0.80805441,  0.80733199,  0.80507939,  0.82684072,  0.82599484,\n",
       "         0.82530729,  0.84106899,  0.83630293,  0.83631481,  0.87427861,\n",
       "         0.87356369,  0.87149533,  0.88869524,  0.88633807,  0.88858192,\n",
       "         0.90019874,  0.89656112,  0.8978531 ,  0.91414816,  0.91157939,\n",
       "         0.91037671,  0.92238851,  0.92559917,  0.92523048,  0.92927515,\n",
       "         0.93164083,  0.92987674,  0.81003025,  0.80607466,  0.80438477,\n",
       "         0.82893546,  0.82593381,  0.82549046,  0.83844827,  0.83605265,\n",
       "         0.83517546,  0.88319802,  0.88048133,  0.87685302,  0.89843631,\n",
       "         0.89688033,  0.89569916,  0.90768031,  0.90568154,  0.90676237,\n",
       "         0.92317753,  0.92287335,  0.92173815,  0.93729627,  0.93741876,\n",
       "         0.93703136,  0.94420277,  0.94447909,  0.94338443,  0.8114754 ,\n",
       "         0.80384238,  0.80428878,  0.82731355,  0.82629166,  0.82659071,\n",
       "         0.83732004,  0.83596232,  0.83616664,  0.87977941,  0.88106055,\n",
       "         0.88064208,  0.90010986,  0.89782695,  0.89891878,  0.90776047,\n",
       "         0.90805915,  0.90754615,  0.92762164,  0.92740155,  0.92815622,\n",
       "         0.94163724,  0.94383755,  0.94273904,  0.94981438,  0.95136543,\n",
       "         0.94922211,  0.81040901,  0.80464726,  0.80611045,  0.82754093,\n",
       "         0.8257661 ,  0.82464732,  0.840183  ,  0.8366453 ,  0.83483808,\n",
       "         0.88267037,  0.88120462,  0.87831246,  0.90102547,  0.89946989,\n",
       "         0.89941503,  0.90892541,  0.90806978,  0.90756958,  0.93133092,\n",
       "         0.93416437,  0.93122283,  0.9473234 ,  0.94582157,  0.94521894,\n",
       "         0.95246436,  0.9533393 ,  0.95252053]),\n",
       " 'param_max_depth': masked_array(data = [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
       "  7 7 7 7 7 7 7 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_weight_fraction_leaf': masked_array(data = [0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.2 0.2 0.2 0.2\n",
       "  0.2 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.05 0.05 0.05\n",
       "  0.05 0.05 0.05 0.05 0.05 0.05],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100\n",
       "  100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120\n",
       "  120 120 70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120\n",
       "  70 70 70 100 100 100 120 120 120 70 70 70 100 100 100 120 120 120 70 70 70\n",
       "  100 100 100 120 120 120],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_subsample': masked_array(data = [0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8\n",
       "  0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8 0.6 0.7 0.8],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 3,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 5,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 7,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.2,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.1,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 70,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.6},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.7},\n",
       "  {'max_depth': 10,\n",
       "   'min_weight_fraction_leaf': 0.05,\n",
       "   'n_estimators': 120,\n",
       "   'subsample': 0.8}],\n",
       " 'rank_test_score': array([101, 100, 104,  88,  91,  92,  75,  81,  79,  65,  64,  71,  50,\n",
       "         60,  46,  39,  37,  38,   9,   3,  10,  14,  13,  30,   1,  19,\n",
       "         25,  98, 106, 102,  87,  95,  89,  78,  74,  77,  54,  67,  69,\n",
       "         57,  47,  53,  43,  59,  49,   5,   6,  20,  16,  29,  21,  23,\n",
       "          4,  35,  97, 103, 107,  82,  94,  83,  84,  86,  76,  68,  66,\n",
       "         72,  40,  51,  62,  55,  56,  44,  31,  27,  12,  11,  22,  17,\n",
       "         34,   2,  41,  99, 105, 108,  90,  93,  96,  73,  85,  80,  61,\n",
       "         63,  70,  42,  48,  58,  33,  52,  45,  18,  15,  24,  32,   7,\n",
       "          8,  28,  36,  26], dtype=int32),\n",
       " 'split0_test_score': array([ 0.76370456,  0.76488238,  0.76298904,  0.7785335 ,  0.7777769 ,\n",
       "         0.77831693,  0.78925089,  0.7851187 ,  0.78357599,  0.80328591,\n",
       "         0.79975045,  0.79515521,  0.81139359,  0.80078042,  0.81371206,\n",
       "         0.81216197,  0.81261464,  0.81283681,  0.81717349,  0.81383924,\n",
       "         0.82108479,  0.81377542,  0.81549574,  0.81424547,  0.82234578,\n",
       "         0.81372278,  0.81473103,  0.76671175,  0.75463062,  0.76260514,\n",
       "         0.7830242 ,  0.78304609,  0.77737397,  0.78575371,  0.78658687,\n",
       "         0.78580024,  0.81222636,  0.80718307,  0.80513791,  0.80751335,\n",
       "         0.80686285,  0.80470805,  0.80403368,  0.80659324,  0.80892977,\n",
       "         0.82328036,  0.81465271,  0.81132237,  0.81513915,  0.81082304,\n",
       "         0.81411573,  0.81135321,  0.81842973,  0.81326585,  0.76448906,\n",
       "         0.75989565,  0.76028924,  0.78421568,  0.78055098,  0.78473254,\n",
       "         0.78734841,  0.78193166,  0.78530786,  0.80689562,  0.80812312,\n",
       "         0.79607657,  0.80710117,  0.80099981,  0.80182909,  0.80805417,\n",
       "         0.80423877,  0.80732269,  0.81953808,  0.80896396,  0.81887851,\n",
       "         0.81749199,  0.80881095,  0.81576212,  0.81238857,  0.80918869,\n",
       "         0.80572346,  0.76657112,  0.76599063,  0.75680368,  0.77896678,\n",
       "         0.78065364,  0.77242233,  0.78910173,  0.7838321 ,  0.78536408,\n",
       "         0.80324982,  0.80449881,  0.79694991,  0.80445518,  0.8108005 ,\n",
       "         0.80295201,  0.81293385,  0.80456102,  0.80497938,  0.82133935,\n",
       "         0.81360429,  0.81515155,  0.81282532,  0.80831837,  0.81454201,\n",
       "         0.81663008,  0.81038367,  0.81091137]),\n",
       " 'split0_train_score': array([ 0.80969173,  0.80909071,  0.80736946,  0.82750515,  0.82975922,\n",
       "         0.82786029,  0.84611438,  0.83767729,  0.83730993,  0.88177066,\n",
       "         0.87942674,  0.87668966,  0.89774554,  0.89081096,  0.89735544,\n",
       "         0.90741904,  0.90211942,  0.90365131,  0.92114761,  0.9177844 ,\n",
       "         0.91432596,  0.92981393,  0.93079685,  0.92944158,  0.93834541,\n",
       "         0.93741834,  0.93572571,  0.80846604,  0.80703335,  0.80716313,\n",
       "         0.83103729,  0.83175896,  0.82899236,  0.84178852,  0.83846697,\n",
       "         0.83629688,  0.89269121,  0.88739883,  0.88281175,  0.90394724,\n",
       "         0.90402427,  0.90224509,  0.91519589,  0.91081107,  0.91349534,\n",
       "         0.9312012 ,  0.92867017,  0.92799826,  0.94351695,  0.94484765,\n",
       "         0.94261364,  0.95088068,  0.94961949,  0.94818562,  0.8073727 ,\n",
       "         0.80720565,  0.80627685,  0.82995338,  0.83128799,  0.83001779,\n",
       "         0.84057665,  0.8402013 ,  0.83749567,  0.88938762,  0.89000507,\n",
       "         0.88463696,  0.90719043,  0.90436072,  0.90559421,  0.91430964,\n",
       "         0.91390496,  0.91627971,  0.93690846,  0.93518284,  0.93425639,\n",
       "         0.94892093,  0.95107513,  0.94982958,  0.9567624 ,  0.95785914,\n",
       "         0.95432432,  0.81265985,  0.80724367,  0.80781043,  0.82818855,\n",
       "         0.83014161,  0.8299033 ,  0.84360018,  0.84159831,  0.83820784,\n",
       "         0.89165121,  0.88878815,  0.8819918 ,  0.90842609,  0.90725132,\n",
       "         0.90709952,  0.91795666,  0.9149563 ,  0.91524428,  0.94005379,\n",
       "         0.94404375,  0.93744267,  0.95475544,  0.95503597,  0.95187279,\n",
       "         0.95912712,  0.96060777,  0.9579873 ]),\n",
       " 'split1_test_score': array([ 0.76075468,  0.75870965,  0.74974986,  0.76981129,  0.77358372,\n",
       "         0.7708017 ,  0.77937438,  0.77652257,  0.77865068,  0.82401387,\n",
       "         0.82666008,  0.82362149,  0.8272947 ,  0.83090153,  0.8300699 ,\n",
       "         0.83097368,  0.83762385,  0.83362943,  0.84792953,  0.8533739 ,\n",
       "         0.84822609,  0.8509711 ,  0.85267735,  0.83794801,  0.85473467,\n",
       "         0.84625794,  0.84526621,  0.76228429,  0.75880559,  0.75734192,\n",
       "         0.77605948,  0.76763011,  0.77050312,  0.78204435,  0.77987596,\n",
       "         0.78078689,  0.82622962,  0.82385384,  0.82265602,  0.8256277 ,\n",
       "         0.83597341,  0.82753839,  0.83892139,  0.83283166,  0.82763266,\n",
       "         0.84524767,  0.8519039 ,  0.85312132,  0.85059326,  0.85056613,\n",
       "         0.84731752,  0.8557647 ,  0.85370435,  0.84744648,  0.76955997,\n",
       "         0.75533571,  0.75554134,  0.77497219,  0.77122838,  0.77359685,\n",
       "         0.77625563,  0.779038  ,  0.77916842,  0.82260804,  0.82439142,\n",
       "         0.8264985 ,  0.83666468,  0.83103515,  0.83442539,  0.83129834,\n",
       "         0.83400736,  0.83087382,  0.84757935,  0.84727011,  0.84629147,\n",
       "         0.84867272,  0.84853608,  0.8474833 ,  0.83705693,  0.85774159,\n",
       "         0.84272203,  0.76535127,  0.75455362,  0.75347071,  0.77290124,\n",
       "         0.77151991,  0.77037173,  0.7809553 ,  0.77882279,  0.77594289,\n",
       "         0.82993128,  0.82805887,  0.82371768,  0.83471668,  0.82820146,\n",
       "         0.83078   ,  0.8400077 ,  0.83374954,  0.83845766,  0.85212823,\n",
       "         0.84863383,  0.84373666,  0.85849292,  0.85196768,  0.84900695,\n",
       "         0.85034167,  0.85141662,  0.84982058]),\n",
       " 'split1_train_score': array([ 0.80749996,  0.80623077,  0.7990928 ,  0.83084195,  0.82820703,\n",
       "         0.82739516,  0.84573398,  0.8384547 ,  0.83919702,  0.87255093,\n",
       "         0.87674661,  0.87528196,  0.88633314,  0.88899623,  0.8872351 ,\n",
       "         0.90026871,  0.8985121 ,  0.89844849,  0.91550845,  0.91460273,\n",
       "         0.91471949,  0.92192897,  0.92826745,  0.92999541,  0.92557502,\n",
       "         0.93117682,  0.93189648,  0.81142722,  0.80800129,  0.80543972,\n",
       "         0.83206136,  0.82508168,  0.82400981,  0.84109831,  0.83768253,\n",
       "         0.8386026 ,  0.88587582,  0.88166078,  0.87986721,  0.90063804,\n",
       "         0.89866177,  0.89768753,  0.90963346,  0.90988544,  0.90890198,\n",
       "         0.9207633 ,  0.92221529,  0.92082864,  0.9378814 ,  0.93688087,\n",
       "         0.93729527,  0.94376624,  0.94485064,  0.94413431,  0.81370015,\n",
       "         0.80166855,  0.80425447,  0.83034404,  0.83065805,  0.82655885,\n",
       "         0.84110468,  0.84077869,  0.83967787,  0.87904331,  0.8809233 ,\n",
       "         0.88207048,  0.90242512,  0.90017768,  0.90170016,  0.9096341 ,\n",
       "         0.91135332,  0.90810901,  0.92599271,  0.92734151,  0.92879018,\n",
       "         0.94058715,  0.94283842,  0.94316829,  0.94740452,  0.94876977,\n",
       "         0.94977058,  0.81419848,  0.80408458,  0.805312  ,  0.8293679 ,\n",
       "         0.82737235,  0.82602692,  0.84227813,  0.84010238,  0.83393938,\n",
       "         0.88172949,  0.88107348,  0.88181261,  0.90358602,  0.89910177,\n",
       "         0.90068   ,  0.91163935,  0.91040912,  0.90905297,  0.93133207,\n",
       "         0.935261  ,  0.93226804,  0.94661521,  0.94600725,  0.94461452,\n",
       "         0.95176635,  0.95260374,  0.95432785]),\n",
       " 'split2_test_score': array([ 0.8261702 ,  0.83027455,  0.8271512 ,  0.83867958,  0.83308   ,\n",
       "         0.83394449,  0.84245555,  0.83574141,  0.8426418 ,  0.87891698,\n",
       "         0.88089177,  0.87401227,  0.881107  ,  0.88065491,  0.8810014 ,\n",
       "         0.88720243,  0.88606526,  0.88471883,  0.89017749,  0.89218528,\n",
       "         0.88583724,  0.88695004,  0.88465811,  0.88952595,  0.88287813,\n",
       "         0.88847216,  0.88460937,  0.83006941,  0.82426655,  0.82085498,\n",
       "         0.83291882,  0.82641543,  0.83765092,  0.83713674,  0.84511957,\n",
       "         0.84210398,  0.87770228,  0.87215602,  0.87088045,  0.88088184,\n",
       "         0.88100435,  0.88396291,  0.88289176,  0.87316261,  0.88593349,\n",
       "         0.88987671,  0.8916884 ,  0.8826744 ,  0.88397397,  0.88090566,\n",
       "         0.88495037,  0.87782074,  0.88642782,  0.87804542,  0.83452447,\n",
       "         0.82498832,  0.82076441,  0.83725441,  0.82798723,  0.83749135,\n",
       "         0.83174942,  0.8317769 ,  0.84470279,  0.86973207,  0.87217692,\n",
       "         0.87002038,  0.88472355,  0.88683263,  0.87413068,  0.8754211 ,\n",
       "         0.87627803,  0.88735999,  0.87408542,  0.88770523,  0.88772652,\n",
       "         0.88775234,  0.88884794,  0.88629553,  0.88948863,  0.89276267,\n",
       "         0.87951512,  0.82547706,  0.81868644,  0.82494585,  0.83342613,\n",
       "         0.82997844,  0.82970007,  0.84614361,  0.83242986,  0.84265524,\n",
       "         0.87798181,  0.8775871 ,  0.87301012,  0.88872008,  0.8836053 ,\n",
       "         0.87891662,  0.88614065,  0.88011691,  0.88140797,  0.87510277,\n",
       "         0.88809141,  0.88590799,  0.86961004,  0.8958776 ,  0.89232597,\n",
       "         0.87676454,  0.87505613,  0.8833247 ]),\n",
       " 'split2_train_score': array([ 0.80697154,  0.80667447,  0.80877592,  0.82217507,  0.82001827,\n",
       "         0.82066643,  0.83135863,  0.83277679,  0.83243749,  0.86851423,\n",
       "         0.86451773,  0.86251437,  0.88200705,  0.87920702,  0.88115521,\n",
       "         0.89290847,  0.88905185,  0.8914595 ,  0.90578842,  0.90235104,\n",
       "         0.90208466,  0.91542264,  0.9177332 ,  0.91625446,  0.923905  ,\n",
       "         0.92632732,  0.92200803,  0.8101975 ,  0.80318936,  0.80055147,\n",
       "         0.82370774,  0.82096078,  0.82346923,  0.83245797,  0.83200847,\n",
       "         0.8306269 ,  0.87102703,  0.87238439,  0.86788011,  0.89072366,\n",
       "         0.88795496,  0.88716486,  0.89821158,  0.89634812,  0.89788981,\n",
       "         0.91756809,  0.91773458,  0.91638754,  0.93049047,  0.93052777,\n",
       "         0.93118517,  0.93796139,  0.93896714,  0.93783335,  0.81335337,\n",
       "         0.80265294,  0.80233502,  0.82164323,  0.81692895,  0.82319548,\n",
       "         0.83027879,  0.82690696,  0.83132639,  0.8709073 ,  0.87225327,\n",
       "         0.87521881,  0.89071402,  0.88894244,  0.88946195,  0.89933767,\n",
       "         0.89891918,  0.89824972,  0.91996374,  0.9196803 ,  0.9214221 ,\n",
       "         0.93540362,  0.93759909,  0.93521926,  0.94527622,  0.94746738,\n",
       "         0.94357142,  0.80436869,  0.80261353,  0.80520893,  0.82506635,\n",
       "         0.81978433,  0.81801172,  0.83467067,  0.82823522,  0.83236701,\n",
       "         0.87463042,  0.87375224,  0.87113299,  0.89106429,  0.89205656,\n",
       "         0.89046557,  0.89718022,  0.89884393,  0.89841148,  0.92260691,\n",
       "         0.92318837,  0.92395778,  0.94059957,  0.93642148,  0.93916952,\n",
       "         0.94649961,  0.94680638,  0.94524644]),\n",
       " 'std_fit_time': array([ 0.00698256,  0.00414394,  0.00411632,  0.00330572,  0.00993558,\n",
       "         0.00173929,  0.00930058,  0.00572545,  0.01524055,  0.00296804,\n",
       "         0.00844861,  0.01048668,  0.00885599,  0.00490641,  0.0054253 ,\n",
       "         0.00117397,  0.00499667,  0.00637261,  0.01035345,  0.0161479 ,\n",
       "         0.01207043,  0.01095387,  0.00473258,  0.00392334,  0.00945296,\n",
       "         0.01981947,  0.00305264,  0.00333241,  0.02053245,  0.02301291,\n",
       "         0.00378615,  0.01030782,  0.01091149,  0.00867736,  0.01369057,\n",
       "         0.00464771,  0.00360093,  0.00150515,  0.00845375,  0.00768358,\n",
       "         0.01079536,  0.00500533,  0.00392486,  0.00510276,  0.00943038,\n",
       "         0.00824651,  0.00921869,  0.01056373,  0.00688025,  0.00875177,\n",
       "         0.01526424,  0.00785441,  0.00754187,  0.00753328,  0.00629972,\n",
       "         0.00831805,  0.00120612,  0.0020205 ,  0.01082341,  0.00125879,\n",
       "         0.00533007,  0.00786638,  0.00465485,  0.00886708,  0.00746505,\n",
       "         0.00786494,  0.00598443,  0.00934915,  0.00436718,  0.01106173,\n",
       "         0.00866871,  0.00564505,  0.00480013,  0.00911531,  0.01277008,\n",
       "         0.03641841,  0.01895965,  0.00905006,  0.01478073,  0.01667915,\n",
       "         0.00383055,  0.00806473,  0.00172486,  0.00524042,  0.00194975,\n",
       "         0.01056354,  0.00700045,  0.00393991,  0.01407023,  0.00839733,\n",
       "         0.00626901,  0.00728131,  0.01022842,  0.00953275,  0.00429673,\n",
       "         0.00437421,  0.01108048,  0.02470039,  0.0022186 ,  0.00371481,\n",
       "         0.00871158,  0.0007405 ,  0.01936364,  0.0255    ,  0.005597  ,\n",
       "         0.02110242,  0.01940607,  0.02447192]),\n",
       " 'std_score_time': array([  1.59202726e-04,   1.47313273e-04,   7.65152378e-05,\n",
       "          2.84260211e-04,   1.75375228e-04,   3.68885570e-04,\n",
       "          1.12703668e-04,   2.74943316e-04,   1.45212421e-04,\n",
       "          2.50873022e-04,   3.37455332e-04,   2.91320469e-04,\n",
       "          3.15713155e-04,   1.97355322e-04,   1.47360942e-04,\n",
       "          1.66417245e-03,   5.34658057e-06,   2.22754699e-04,\n",
       "          2.16937442e-04,   9.07182606e-05,   1.11767890e-04,\n",
       "          3.43020348e-04,   2.33354268e-04,   1.89562599e-03,\n",
       "          3.46662600e-04,   2.77893284e-04,   2.16423961e-04,\n",
       "          2.07349549e-05,   1.10784767e-04,   3.37897609e-04,\n",
       "          6.26234718e-04,   1.61282489e-04,   2.93188316e-04,\n",
       "          1.99623548e-04,   1.15877698e-04,   2.77745331e-04,\n",
       "          9.16128022e-05,   2.55684409e-04,   3.11350969e-03,\n",
       "          1.03758568e-04,   2.35877188e-04,   2.29497344e-03,\n",
       "          2.11577232e-04,   8.09333241e-04,   2.04058171e-04,\n",
       "          1.94449252e-04,   1.53240820e-04,   7.38508372e-04,\n",
       "          3.38470720e-04,   1.32943296e-03,   2.78967420e-04,\n",
       "          2.03920327e-04,   1.10956351e-04,   1.18544153e-04,\n",
       "          1.67351539e-04,   2.06233617e-04,   1.59208200e-04,\n",
       "          3.16032877e-04,   1.06682835e-04,   2.32139475e-04,\n",
       "          5.24307699e-05,   8.24667161e-05,   2.71086293e-04,\n",
       "          1.21615186e-04,   1.34048218e-04,   1.46833889e-04,\n",
       "          2.97569841e-04,   2.21654319e-03,   2.01838128e-04,\n",
       "          1.17621351e-03,   2.61682128e-04,   4.40565322e-04,\n",
       "          2.62448889e-04,   2.58698771e-04,   2.72815963e-04,\n",
       "          4.70003164e-04,   3.85100402e-04,   2.04317010e-04,\n",
       "          3.62502485e-04,   1.82672444e-04,   3.93931197e-04,\n",
       "          1.01640226e-04,   1.63856116e-04,   5.02499583e-04,\n",
       "          1.38726746e-04,   1.74892049e-04,   2.65621961e-03,\n",
       "          3.45913854e-04,   2.94078727e-04,   3.46225390e-04,\n",
       "          7.05915859e-05,   1.69768352e-04,   1.26960673e-04,\n",
       "          3.89688488e-04,   4.97674099e-04,   3.31410706e-04,\n",
       "          4.65684538e-04,   6.58577352e-05,   9.71580982e-05,\n",
       "          1.01989847e-04,   9.95768610e-05,   5.46373905e-04,\n",
       "          2.10412287e-04,   1.94189880e-04,   7.37381382e-05,\n",
       "          1.82131925e-03,   1.86874578e-04,   2.75216636e-04]),\n",
       " 'std_test_score': array([ 0.03015119,  0.03236362,  0.03378603,  0.03060214,  0.02709938,\n",
       "         0.02814858,  0.02769081,  0.02611431,  0.02906029,  0.03189625,\n",
       "         0.03373294,  0.03259345,  0.02981696,  0.03292366,  0.02864145,\n",
       "         0.03186551,  0.03047888,  0.0301896 ,  0.02991708,  0.03197738,\n",
       "         0.02654153,  0.0298677 ,  0.02825615,  0.03141511,  0.02472728,\n",
       "         0.03059211,  0.02859445,  0.03094837,  0.03187268,  0.02876616,\n",
       "         0.02531019,  0.02487636,  0.03015047,  0.0251299 ,  0.0292886 ,\n",
       "         0.02778546,  0.02813895,  0.02754111,  0.02778618,  0.03119198,\n",
       "         0.03048944,  0.03329669,  0.03225512,  0.02736975,  0.03277854,\n",
       "         0.02769683,  0.03144714,  0.02926739,  0.02809947,  0.02869175,\n",
       "         0.02892901,  0.02764022,  0.02776032,  0.02645385,  0.03187155,\n",
       "         0.03179879,  0.02967626,  0.02742916,  0.02484056,  0.02785581,\n",
       "         0.02396606,  0.02419634,  0.02953831,  0.02668834,  0.02717282,\n",
       "         0.03033504,  0.03197643,  0.03555004,  0.0295559 ,  0.02792871,\n",
       "         0.02954757,  0.0335708 ,  0.02226664,  0.03214159,  0.02829119,\n",
       "         0.02873546,  0.03266712,  0.02883516,  0.03213634,  0.03426212,\n",
       "         0.030118  ,  0.02804672,  0.02791689,  0.03292014,  0.02720181,\n",
       "         0.02566491,  0.02748361,  0.02898741,  0.02416487,  0.02946592,\n",
       "         0.03091077,  0.03044752,  0.03149032,  0.03484038,  0.03102921,\n",
       "         0.03136832,  0.03021143,  0.03109941,  0.03127213,  0.0220222 ,\n",
       "         0.03041881,  0.0290535 ,  0.02457285,  0.03573713,  0.03181416,\n",
       "         0.0246053 ,  0.026716  ,  0.0295839 ]),\n",
       " 'std_train_score': array([ 0.00117769,  0.00125673,  0.00427192,  0.0035693 ,  0.00427331,\n",
       "         0.00328707,  0.00686802,  0.00251347,  0.00284786,  0.00554809,\n",
       "         0.00648937,  0.00637645,  0.00663876,  0.00509655,  0.00668193,\n",
       "         0.00592412,  0.0055103 ,  0.00499506,  0.00634371,  0.00665345,\n",
       "         0.00586556,  0.0058842 ,  0.00565712,  0.00635103,  0.00644978,\n",
       "         0.00453977,  0.00577946,  0.00121467,  0.00207814,  0.00280038,\n",
       "         0.00372012,  0.00444932,  0.00248603,  0.00424514,  0.00287755,\n",
       "         0.00335123,  0.00904478,  0.00618609,  0.00645768,  0.00561851,\n",
       "         0.00668011,  0.00631498,  0.00707002,  0.00661054,  0.00654811,\n",
       "         0.00582162,  0.00448862,  0.00478349,  0.00533411,  0.00585843,\n",
       "         0.00466938,  0.0052833 ,  0.00435674,  0.00425943,  0.0029045 ,\n",
       "         0.00241191,  0.00160943,  0.00401269,  0.00662543,  0.00278529,\n",
       "         0.00498358,  0.00640744,  0.00353662,  0.00756249,  0.00724779,\n",
       "         0.00397539,  0.00692283,  0.00651026,  0.00687336,  0.00625422,\n",
       "         0.00654635,  0.00737146,  0.00701289,  0.00632903,  0.00525872,\n",
       "         0.00556815,  0.00554675,  0.00597235,  0.00498923,  0.00462243,\n",
       "         0.00440695,  0.00431709,  0.00193167,  0.0012028 ,  0.00181482,\n",
       "         0.00437823,  0.00495176,  0.00393499,  0.0059781 ,  0.00246773,\n",
       "         0.00698048,  0.00613909,  0.00507718,  0.00731552,  0.00620869,\n",
       "         0.00684944,  0.00869633,  0.00678265,  0.00695155,  0.00712266,\n",
       "         0.00854941,  0.00555457,  0.00580076,  0.00760047,  0.00520367,\n",
       "         0.00517873,  0.00565835,  0.00535613])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.1,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=0.7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17198.96120694  23195.83272626  21463.95294502  20761.49425872\n",
      "  20182.72379423  22025.80395473  18995.875571    18174.82013286\n",
      "  15579.48662801  16773.60645665]\n",
      "[ 0.86531833  0.77064438  0.79723221  0.90047097  0.83797817  0.7653455\n",
      "  0.85238884  0.84791002  0.90572437  0.86144469]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def score_dataset_cv(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor(n_estimators= 100, max_depth=5, subsample= 0.7\n",
    "                                      ,min_weight_fraction_leaf=0.1)\n",
    "    scores = cross_validate(model, X_train, y_train,\n",
    "                         scoring=('r2', 'neg_mean_absolute_error'), cv=10)\n",
    "    print(-scores['test_neg_mean_absolute_error'])      \n",
    "    print(scores['test_r2'])                         \n",
    "\n",
    "score_dataset_cv(reduced_X_train, reduced_X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
